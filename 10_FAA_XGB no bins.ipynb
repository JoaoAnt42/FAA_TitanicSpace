{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.413404Z","iopub.status.busy":"2022-10-19T15:25:10.413012Z","iopub.status.idle":"2022-10-19T15:25:10.425089Z","shell.execute_reply":"2022-10-19T15:25:10.423712Z","shell.execute_reply.started":"2022-10-19T15:25:10.413371Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","import xgboost as xgb\n","import joblib\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import cross_val_score, HalvingGridSearchCV\n","from sklearn.metrics import plot_roc_curve\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import ElasticNet, ElasticNetCV\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.ensemble import ExtraTreesClassifier\n","import matplotlib.patches as patches  # extra code â€“ for the curved arrow\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import precision_score, recall_score\n","import lightgbm as lgb\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import precision_score, recall_score\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import learning_curve\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n","from sklearn.compose import make_column_selector, make_column_transformer\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.403718Z","iopub.status.busy":"2022-10-19T15:25:10.403280Z","iopub.status.idle":"2022-10-19T15:25:10.410978Z","shell.execute_reply":"2022-10-19T15:25:10.409611Z","shell.execute_reply.started":"2022-10-19T15:25:10.403683Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def pandas_preprocessing(X, y_present=True):\n","  X['PassengerId_split'] = X['PassengerId'].apply(lambda x : str(x).split(sep = '_', maxsplit=1))\n","  X['Group']= X['PassengerId_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[0])\n","  X['Group_id']= X['PassengerId_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[1])\n","  X = X.drop(['PassengerId','PassengerId_split'],axis=1)\n","\n","  # Split the names\n","  X['Name_split'] = X['Name'].apply(lambda x : str(x).split(sep = ' ', maxsplit=1))\n","  X['Surname']= X['Name_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[1])\n","  X = X.drop(['Name','Name_split'],axis=1)\n","\n","  # Split the cabins\n","  X['Cabin_splt'] = X['Cabin'].apply(lambda x : str(x).split(sep = '/'))\n","  X['Deck']= X['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[0])\n","  X['CabinNumber']= X['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[1]).astype('float')\n","  X['CabinSide']= X['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[2])\n","  X = X.drop(['Cabin','Cabin_splt'],axis=1)\n","\n","  # Create Total\n","  numeric_cols = list(X.select_dtypes(include = np.number).columns)\n","  X['Total'] = sum(X[col] for col in numeric_cols if col not in [\"Age\", \"CabinNumber\"])\n","  # X['age'] = pd.cut(x=X['Age'], bins=range(0, 90, 10))\n","  # X['total'] = pd.cut(x=X['Total'], bins=[-35.987, 3598.7, 7197.4, 10796.1, 14394.8, 17993.5, 21592.2, 25190.9, 28789.6, 32388.3, 35987.])\n","  # X = X.drop(['Age', \"Total\"],axis=1)\n","  # X['age'] = X['age'].astype('str') \n","  # X['total'] = X['total'].astype('str')\n","  target = X['Transported']\n","  target = target.astype(int)\n","  X = X.drop(['Transported'],axis=1)\n","  return X, target"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["bol_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    )\n","\n","cat_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n","    )\n","\n","\n","num_pipeline = make_pipeline(\n","    SimpleImputer(strategy='median'),\n","    StandardScaler()\n",")\n","\n","preprocessing_pipe = make_column_transformer(\n","    (num_pipeline, make_column_selector(dtype_include=np.number)),\n","    (cat_pipeline, make_column_selector(dtype_include=object)),\n","    (bol_pipeline, make_column_selector(dtype_include=bool)),\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df = pd.read_csv('data_FAA/train.csv')\n","df, y = pandas_preprocessing(df)\n","df_prepared = preprocessing_pipe.fit_transform(df)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df_prepared_fr = pd.DataFrame(\n","    df_prepared,\n","    columns=preprocessing_pipe.get_feature_names_out(),\n","    index=df.index)\n","df_prepared_fr.head()\n","X_train, X_test, y_train, y_test = train_test_split(df_prepared_fr, y, test_size = 0.2, random_state = 100)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import joblib\n","with open('data_FAA/data3.pkl', 'wb') as f:\n","    joblib.dump([X_train, y_train, X_test, y_test], f)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X_train, y_train, X_test, y_test = joblib.load('data_FAA/data3.pkl')\n","redo_grid_search = 0\n","cm = 0"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["if redo_grid_search:\n","  PARAMETERS = {'booster' : ['gbtree', \"dart\"],\n","                'gamma': [1, 5,],\n","                'eta': [0.05],\n","                'learning_rate': [0.05,0.1],\n","                \"subsample\": [1], \n","                'max_depth': [8, 10],\n","                'n_estimators': [600, 1000],\n","                \"colsample_bytree\": [0.5,0.88],\n","                \"scale_pos_weight\": [1,],\n","                'reg_alpha': [0,1],\n","                'reg_lambda': [2,],}\n","\n","  # HalvingGridSearchCV\n","  grid_search_xgb = HalvingGridSearchCV(estimator=lgb.LGBMClassifer(),param_grid=PARAMETERS,verbose = 1,\n","                                                            cv = 10,scoring='accuracy',max_resources=1000,random_state = 0,\n","                                                            resource='n_samples',n_jobs=-1).fit(X_train.values, y_train.values.ravel())\n","\n","  lbg_best = grid_search_xgb.best_estimator_\n","  print(\"LGBM Classifer\")\n","  print('LGBM Classifer Best Score',grid_search_xgb.best_score_)\n","  print('LGBM Classifer Best Parmas',grid_search_xgb.best_params_)\n","  print('LGBM Classifer Accuracy',cross_val_score(lbg_best,X_train.values, y_train.values.ravel(), cv=10).mean())\n","else:\n","  xbg_best = xgb.XGBClassifier(booster='dart', colsample_bytree=0.88, gamma=5, learning_rate=0.1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m cross_val_predict(xbg_best, X_train, y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:968\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 968\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    969\u001b[0m     delayed(_fit_and_predict)(\n\u001b[1;32m    970\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[1;32m    971\u001b[0m     )\n\u001b[1;32m    972\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m splits\n\u001b[1;32m    973\u001b[0m )\n\u001b[1;32m    975\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m    976\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:1050\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1049\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1050\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1051\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m   1052\u001b[0m predictions \u001b[39m=\u001b[39m func(X_test)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/xgboost/sklearn.py:1516\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m (\n\u001b[1;32m   1489\u001b[0m     model,\n\u001b[1;32m   1490\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1496\u001b[0m )\n\u001b[1;32m   1497\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1498\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1499\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1514\u001b[0m )\n\u001b[0;32m-> 1516\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1517\u001b[0m     params,\n\u001b[1;32m   1518\u001b[0m     train_dmatrix,\n\u001b[1;32m   1519\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1520\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1521\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1522\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1523\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1524\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1525\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1526\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1527\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1528\u001b[0m )\n\u001b[1;32m   1530\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1531\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/Documents/FAA_TitanicSpace/env_FAA/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["y_pred = cross_val_predict(xbg_best, X_train, y_train, cv=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import RocCurveDisplay\n","xbg_best.fit(X_train, y_train)\n","RocCurveDisplay.from_estimator(\n","   xbg_best, X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import PrecisionRecallDisplay\n","PrecisionRecallDisplay.from_estimator(\n","   xbg_best, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n","RocCurveDisplay.from_estimator(\n","   xbg_best, X_test, y_test, ax=ax[1, 1])\n","\n","\n","PrecisionRecallDisplay.from_estimator(\n","   xbg_best, X_test, y_test, ax=ax[1, 0])\n","\n","ConfusionMatrixDisplay.from_predictions(y_train, y_pred, ax=ax[0, 0])\n","ConfusionMatrixDisplay.from_predictions(y_train, y_pred, normalize=\"true\", ax=ax[0, 1])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","\n","# always use same RANDOM_STATE k-folds for comparability between tests, reproducibility\n","RANDOMSTATE = 42\n","np.random.seed(RANDOMSTATE)\n","\n","kfolds = KFold(n_splits=20, shuffle=True, random_state=RANDOMSTATE)\n","\n","MEAN_RESPONSE=y_train.mean()\n","def cv_to_raw(cv_val, mean_response=MEAN_RESPONSE):\n","    return np.expm1(mean_response+cv_val) - np.expm1(mean_response)\n","\t\n","scores = -cross_val_score(xbg_best, X_train, y_train,\n","                          scoring=\"neg_root_mean_squared_error\",\n","                          cv=kfolds,\n","                          n_jobs=-1)\n","raw_scores = [cv_to_raw(x) for x in scores]\n","print(\"Raw CV RMSE %.0f (STD %.0f)\" % (np.mean(raw_scores), np.std(raw_scores)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_scores = sum(score for score, name in zip(xbg_best.feature_importances_, X_train.columns))\n","\n","for score, name in zip(xbg_best.feature_importances_, X_train.columns):\n","    print(f\"{score/max_scores * 100:.1f}% {' ':>20}{name.split('__', 1)[1]:>20}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_sizes, train_scores, valid_scores = learning_curve(\n","    xbg_best, X_train, y_train, train_sizes=np.linspace(0.01, 1.0, 40), cv=5,\n","    scoring=\"neg_root_mean_squared_error\")\n","train_errors = -train_scores.mean(axis=1)\n","valid_errors = -valid_scores.mean(axis=1)\n","\n","plt.figure(figsize=(6, 4))  # extra code â€“ not needed, just formatting\n","plt.plot(train_sizes, train_errors, \"r-+\", linewidth=2, label=\"train\")\n","plt.plot(train_sizes, valid_errors, \"b-\", linewidth=3, label=\"valid\")\n","\n","# extra code â€“ beautifies and saves Figure 4â€“15\n","plt.xlabel(\"Training set size\")\n","plt.ylabel(\"RMSE\")\n","plt.grid()\n","plt.legend(loc=\"upper right\")\n","# plt.axis([0, 1000, 0.3, 0.9])\n","# plt.save_fig(\"underfitting_learning_curves_plot\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#----------------For submission----------------\n","data1= pd.read_csv(\"data_FAA/train.csv\")\n","data2 = pd.read_csv(\"data_FAA/evaluation.csv\")\n","data2 = pd.read_csv(\"data_FAA/evaluation.csv\")\n","data2['Transported'] =-1\n","\n","data1, y1 = pandas_preprocessing(data1)\n","data2, y2 = pandas_preprocessing(data2)\n","\n","data1 = preprocessing_pipe.fit_transform(data1)\n","data2 = preprocessing_pipe.transform(data2)\n","\n","xbg_best.fit(data1, y1)\n","\n","pred = xbg_best.predict(data2)\n","\n","pred = pred.astype(bool)\n","result=pd.read_csv('data_FAA/sample_submission.csv')\n","result['Transported'] = pred\n","result.to_csv('submission_xgb.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 ('env_FAA': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"540857b334b17b7c8f347a05d47e5b62911a011d1f5b5a830e95133110947623"}}},"nbformat":4,"nbformat_minor":4}
