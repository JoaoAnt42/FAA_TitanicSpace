{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Original Description\n","> Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",">\n","> The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",">\n","> While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",">\n","> To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n",">\n","> Help save them and change history!"]},{"cell_type":"markdown","metadata":{},"source":["### Features\n","- `PassengerId` - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n","- `HomePlanet` - The planet the passenger departed from, typically their planet of permanent residence.\n","- `CryoSleep` - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n","- `Cabin` - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n","- `Destination` - The planet the passenger will be debarking to.\n","- `Age` - The age of the passenger.\n","- `VIP` - Whether the passenger has paid for special VIP service during the voyage.\n","- `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck` - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n","- `Name` - The first and last names of the passenger.\n","\n","### Labels\n","- `Transported` - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict."]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# !pip3 install -r requirements.txt"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.413404Z","iopub.status.busy":"2022-10-19T15:25:10.413012Z","iopub.status.idle":"2022-10-19T15:25:10.425089Z","shell.execute_reply":"2022-10-19T15:25:10.423712Z","shell.execute_reply.started":"2022-10-19T15:25:10.413371Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from lazypredict.Supervised import LazyClassifier\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.403718Z","iopub.status.busy":"2022-10-19T15:25:10.403280Z","iopub.status.idle":"2022-10-19T15:25:10.410978Z","shell.execute_reply":"2022-10-19T15:25:10.409611Z","shell.execute_reply.started":"2022-10-19T15:25:10.403683Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["redo_graphs = 0"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.440800Z","iopub.status.busy":"2022-10-19T15:25:10.439811Z","iopub.status.idle":"2022-10-19T15:25:10.506203Z","shell.execute_reply":"2022-10-19T15:25:10.504969Z","shell.execute_reply.started":"2022-10-19T15:25:10.440766Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>HomePlanet</th>\n","      <th>CryoSleep</th>\n","      <th>Cabin</th>\n","      <th>Destination</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Name</th>\n","      <th>Transported</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0001_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>B/0/P</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>39.00</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>Maham Ofracculy</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>24.00</td>\n","      <td>False</td>\n","      <td>109.00</td>\n","      <td>9.00</td>\n","      <td>25.00</td>\n","      <td>549.00</td>\n","      <td>44.00</td>\n","      <td>Juanna Vines</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0003_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>58.00</td>\n","      <td>True</td>\n","      <td>43.00</td>\n","      <td>3576.00</td>\n","      <td>0.00</td>\n","      <td>6715.00</td>\n","      <td>49.00</td>\n","      <td>Altark Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0003_02</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>33.00</td>\n","      <td>False</td>\n","      <td>0.00</td>\n","      <td>1283.00</td>\n","      <td>371.00</td>\n","      <td>3329.00</td>\n","      <td>193.00</td>\n","      <td>Solam Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0004_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/1/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>16.00</td>\n","      <td>False</td>\n","      <td>303.00</td>\n","      <td>70.00</td>\n","      <td>151.00</td>\n","      <td>565.00</td>\n","      <td>2.00</td>\n","      <td>Willy Santantines</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n","0     0001_01     Europa     False  B/0/P  TRAPPIST-1e 39.00  False   \n","1     0002_01      Earth     False  F/0/S  TRAPPIST-1e 24.00  False   \n","2     0003_01     Europa     False  A/0/S  TRAPPIST-1e 58.00   True   \n","3     0003_02     Europa     False  A/0/S  TRAPPIST-1e 33.00  False   \n","4     0004_01      Earth     False  F/1/S  TRAPPIST-1e 16.00  False   \n","\n","   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n","0         0.00       0.00          0.00    0.00    0.00    Maham Ofracculy   \n","1       109.00       9.00         25.00  549.00   44.00       Juanna Vines   \n","2        43.00    3576.00          0.00 6715.00   49.00      Altark Susent   \n","3         0.00    1283.00        371.00 3329.00  193.00       Solam Susent   \n","4       303.00      70.00        151.00  565.00    2.00  Willy Santantines   \n","\n","   Transported  \n","0        False  \n","1         True  \n","2        False  \n","3        False  \n","4         True  "]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["try:\n","    df = pd.read_csv('data_FAA/train.csv')\n","    # df_test = pd.read_csv('../input/spaceship-titanic/test.csv')\n","except FileNotFoundError:\n","    df = pd.read_csv('data_FAA/train.csv')\n","    # df_test = pd.read_csv('/spaceship-titanic/test.csv')\n","df.head()"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T15:25:10.509891Z","iopub.status.busy":"2022-10-19T15:25:10.509398Z","iopub.status.idle":"2022-10-19T15:25:10.546670Z","shell.execute_reply":"2022-10-19T15:25:10.545317Z","shell.execute_reply.started":"2022-10-19T15:25:10.509825Z"},"trusted":true},"outputs":[],"source":["def preprocess(df, preTrain = True, rem_columns=True):\n","    # drop the entire cols that have low to now interest for now\n","    if preTrain:\n","        df = df.dropna()\n","\n","    df['PassengerId_split'] = df['PassengerId'].apply(lambda x : str(x).split(sep = '_', maxsplit=1))\n","    df['Group']= df['PassengerId_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[0])\n","    df['Group_id']= df['PassengerId_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[1])\n","    df = df.drop(['PassengerId','PassengerId_split'],axis=1)\n","\n","    df['Name_split'] = df['Name'].apply(lambda x : str(x).split(sep = ' ', maxsplit=1))\n","    df['FirstName']= df['Name_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[0])\n","    df['Surname']= df['Name_split'].apply(lambda x : np.nan if x[0] == 'nan' else x[1])\n","    df = df.drop(['Name','Name_split'],axis=1)\n","\n","    # Split the cabins\n","    df['Cabin_splt'] = df['Cabin'].apply(lambda x : str(x).split(sep = '/'))\n","\n","    df['Deck']= df['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[0])\n","    df['CabinNumber']= df['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[1]).astype('float')\n","    df['CabinSide']= df['Cabin_splt'].apply(lambda x : np.nan if x[0] == 'nan' else x[2])\n","\n","    df = df.drop(['Cabin','Cabin_splt'],axis=1)\n","\n","    numeric_cols = list(df.select_dtypes(include = np.number).columns)\n","    category_cols = list(df.select_dtypes(include = ['object']).columns)\n","    # processing categorical null value\n","    for col in category_cols:\n","        df[col] = df[col].fillna(df[col].mode()[0])\n","\n","    # processing numerical null value\n","    for col in numeric_cols:\n","        df[col] = df[col].fillna(df[col].mode()[0])\n","\n","    df_n=df[numeric_cols]\n","    df_c=df[category_cols]\n","\n","    df_n['Total'] = sum(df[col] for col in numeric_cols if col not in [\"Age\", \"CabinNumber\"])\n","\n","    # Categorize the Total Spending 0.43\n","    df_n['cat_Total'] = ''\n","    list_spend = [0, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n","    for k in range(len(list_spend)-1):\n","        df_n.loc[df_n['Total'].between(list_spend[k], list_spend[k+1], 'right'), 'cat_Total'] = f'Under{list_spend[k+1]}'\n","    df_n.loc[df_n['Total'].between(list_spend[-1], 9999999, 'both'), 'cat_Total'] = 'rest'\n","\n","    df_n['cat_Total'] = df_n['cat_Total'].astype('category').cat.codes.astype(\"int\") \n","\n","    # Dividing in intervals of 10 gave a correlation of -0.09 to Transported, diving into 4 categories gave a -0.12\n","    df_n['cat_Age'] = ''\n","    for k in range(20):\n","        df_n.loc[df_n['Age'].between(5*k, 5*(k+1), 'both'), 'cat_Age'] = f'Under{k*5}'\n","    df_n['cat_Age'] = df_n['cat_Age'].astype('category').cat.codes.astype(\"int\")   \n","\n","    if rem_columns:\n","        df_n = df_n.drop(['Age', \"Total\"],axis=1)\n","    df_n[\"Transported\"] = df[\"Transported\"]\n","\n","    numeric_cols = list(df.select_dtypes(include = np.number).columns)\n","    category_cols = list(df.select_dtypes(include = ['object']).columns)\n","    bool_cols  = list(df.select_dtypes(include = bool).columns)\n","\n","    for col in bool_cols:\n","        if col != \"Transported\":\n","            df_n[f\"boo_{col}\"] = df[col]\n","\n","    # label encode\n","    enc = LabelEncoder()\n","    for col in category_cols:\n","        enc.fit(df_c[col])\n","        df_c[col] = enc.transform(df_c[col])\n","        df_n[f\"cat_{col}\"] = df_c[col]\n","    category_cols.extend((\"cat_Age\", \"cat_Total\"))\n","    print(f\"Boolean columns ({len(bool_cols)}) :\", \", \".join(bool_cols))\n","    print(f\"Numeric columns ({len(numeric_cols)}) :\", \", \".join(numeric_cols))\n","    print(f\"Categorical columns ({len(category_cols)}) :\", \", \".join(category_cols))\n","\n","    return df_n, category_cols, numeric_cols, bool_cols\n","\n","def split_x_y(df, preTrain = True):\n","    target = df['Transported']\n","    target = target.astype(int)\n","    df = df.drop(['Age', \"Total\"],axis=1)\n","    df = df.drop(['Transported'],axis=1)\n","    return df, target"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Boolean columns (3) : CryoSleep, VIP, Transported\n","Numeric columns (7) : Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber\n","Categorical columns (10) : HomePlanet, Destination, Group, Group_id, FirstName, Surname, Deck, CabinSide, cat_Age, cat_Total\n"]}],"source":["# initiate the traning and test datasets--for trainning\n","df_n, category_cols, numeric_cols, bool_cols = preprocess(df, rem_columns=False)\n","df_test, df_train = train_test_split(df_n, test_size = 0.2, random_state = 100)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["X_train, y_train = split_x_y(df_train)\n","X_test, y_test = split_x_y(df_test)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 29/29 [00:03<00:00,  8.68it/s]\n"]}],"source":["clf = LazyClassifier(verbose=0,\n","                     ignore_warnings=True,\n","                     custom_metric=None,\n","                     predictions=False,\n","                     random_state=12,\n","                     classifiers='all')\n","\n","models, predictions = clf.fit(X_train , X_test , y_train , y_test)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Balanced Accuracy</th>\n","      <th>ROC AUC</th>\n","      <th>F1 Score</th>\n","      <th>Time Taken</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LGBMClassifier</th>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.13</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestClassifier</th>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.27</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesClassifier</th>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.79</td>\n","      <td>0.27</td>\n","    </tr>\n","    <tr>\n","      <th>XGBClassifier</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.14</td>\n","    </tr>\n","    <tr>\n","      <th>CalibratedClassifierCV</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.34</td>\n","    </tr>\n","    <tr>\n","      <th>NuSVC</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.45</td>\n","    </tr>\n","    <tr>\n","      <th>LinearSVC</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.11</td>\n","    </tr>\n","    <tr>\n","      <th>SVC</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>LogisticRegression</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>AdaBoostClassifier</th>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.78</td>\n","      <td>0.19</td>\n","    </tr>\n","    <tr>\n","      <th>BaggingClassifier</th>\n","      <td>0.77</td>\n","      <td>0.77</td>\n","      <td>0.77</td>\n","      <td>0.77</td>\n","      <td>0.09</td>\n","    </tr>\n","    <tr>\n","      <th>BernoulliNB</th>\n","      <td>0.75</td>\n","      <td>0.75</td>\n","      <td>0.75</td>\n","      <td>0.75</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>RidgeClassifierCV</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>RidgeClassifier</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>LinearDiscriminantAnalysis</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>NearestCentroid</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>Perceptron</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsClassifier</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.20</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeClassifier</th>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.73</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>SGDClassifier</th>\n","      <td>0.72</td>\n","      <td>0.72</td>\n","      <td>0.72</td>\n","      <td>0.72</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>QuadraticDiscriminantAnalysis</th>\n","      <td>0.72</td>\n","      <td>0.72</td>\n","      <td>0.72</td>\n","      <td>0.71</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>PassiveAggressiveClassifier</th>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeClassifier</th>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LabelPropagation</th>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>LabelSpreading</th>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>GaussianNB</th>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.70</td>\n","      <td>0.68</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>DummyClassifier</th>\n","      <td>0.50</td>\n","      <td>0.50</td>\n","      <td>0.50</td>\n","      <td>0.33</td>\n","      <td>0.01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n","Model                                                                           \n","LGBMClassifier                     0.79               0.79     0.79      0.79   \n","RandomForestClassifier             0.79               0.79     0.79      0.79   \n","ExtraTreesClassifier               0.79               0.79     0.79      0.79   \n","XGBClassifier                      0.78               0.78     0.78      0.78   \n","CalibratedClassifierCV             0.78               0.78     0.78      0.78   \n","NuSVC                              0.78               0.78     0.78      0.78   \n","LinearSVC                          0.78               0.78     0.78      0.78   \n","SVC                                0.78               0.78     0.78      0.78   \n","LogisticRegression                 0.78               0.78     0.78      0.78   \n","AdaBoostClassifier                 0.78               0.78     0.78      0.78   \n","BaggingClassifier                  0.77               0.77     0.77      0.77   \n","BernoulliNB                        0.75               0.75     0.75      0.75   \n","RidgeClassifierCV                  0.73               0.73     0.73      0.73   \n","RidgeClassifier                    0.73               0.73     0.73      0.73   \n","LinearDiscriminantAnalysis         0.73               0.73     0.73      0.73   \n","NearestCentroid                    0.73               0.73     0.73      0.73   \n","Perceptron                         0.73               0.73     0.73      0.73   \n","KNeighborsClassifier               0.73               0.73     0.73      0.73   \n","DecisionTreeClassifier             0.73               0.73     0.73      0.73   \n","SGDClassifier                      0.72               0.72     0.72      0.72   \n","QuadraticDiscriminantAnalysis      0.72               0.72     0.72      0.71   \n","PassiveAggressiveClassifier        0.70               0.70     0.70      0.70   \n","ExtraTreeClassifier                0.70               0.70     0.70      0.70   \n","LabelPropagation                   0.70               0.70     0.70      0.70   \n","LabelSpreading                     0.70               0.70     0.70      0.70   \n","GaussianNB                         0.70               0.70     0.70      0.68   \n","DummyClassifier                    0.50               0.50     0.50      0.33   \n","\n","                               Time Taken  \n","Model                                      \n","LGBMClassifier                       0.13  \n","RandomForestClassifier               0.27  \n","ExtraTreesClassifier                 0.27  \n","XGBClassifier                        0.14  \n","CalibratedClassifierCV               0.34  \n","NuSVC                                0.45  \n","LinearSVC                            0.11  \n","SVC                                  0.50  \n","LogisticRegression                   0.02  \n","AdaBoostClassifier                   0.19  \n","BaggingClassifier                    0.09  \n","BernoulliNB                          0.02  \n","RidgeClassifierCV                    0.02  \n","RidgeClassifier                      0.02  \n","LinearDiscriminantAnalysis           0.03  \n","NearestCentroid                      0.02  \n","Perceptron                           0.02  \n","KNeighborsClassifier                 0.20  \n","DecisionTreeClassifier               0.02  \n","SGDClassifier                        0.03  \n","QuadraticDiscriminantAnalysis        0.02  \n","PassiveAggressiveClassifier          0.02  \n","ExtraTreeClassifier                  0.01  \n","LabelPropagation                     0.18  \n","LabelSpreading                       0.18  \n","GaussianNB                           0.02  \n","DummyClassifier                      0.01  "]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tentar visualizar a dependência de Transported com as variáveis binárias (ou com poucos elementos)\n","# Fazer o mesmo com as novas features (p.e. Age depois de agrupar)\n","fig, axes = plt.subplots(3, 2, figsize=(12,12),sharey=True)\n","\n","k = 0\n","for col in cat_columns:\n","    if col not in [\"cat_Group\", \"cat_Surname\", \"cat_FirstName\", \"cat_HomePlanet\"]:\n","        sns.countplot(ax=axes[k%3, k//3],hue='Transported',x=col,data=df_train)\n","        k += 1\n","plt.savefig(\"Imagens_FAA/4graphs.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# #  Tentar visualizar a dependência de Transported com as restantes variáveis através de boxplots\n","# sns.boxplot(x='Transported',y='Age',data=df_train)\n","# plt.savefig(\"Imagens_FAA/Age.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Não dá para visualizar muito bem porque a maior parte dos valores é dada como outlier\n","if redo_graphs:\n","    sns.boxplot(x='Transported',y='VRDeck',data=df_train)\n","    plt.savefig(\"Imagens_FAA/Boxplot_VRDeck.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if redo_graphs:\n","    num_columns.append(\"Transported\")\n","    sns.pairplot(df_train[num_columns], kind=\"scatter\", hue=\"Transported\")\n","    plt.savefig(\"Imagens_FAA/Full_pairplot_cont.png\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if redo_graphs:\n","    sns.pairplot(df_train, kind=\"scatter\", hue=\"Transported\")\n","    plt.show()\n","    plt.savefig(\"Imagens_FAA/Full_pairplot.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if redo_graphs:\n","    corr = df_train.corr()\n","    # Generate a mask for the upper triangle\n","    mask = np.triu(np.ones_like(corr, dtype=bool))\n","\n","    # Set up the matplotlib figure\n","    f, ax = plt.subplots(figsize=(11, 9))\n","\n","    # Generate a custom diverging colormap\n","    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n","\n","    # Draw the heatmap with the mask and correct aspect ratio\n","    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n","                square=True, linewidths=.4, cbar_kws={\"shrink\": .5})\n","    # Not sure of the reason why but the below command saves it some with border\n","    plt.savefig(\"Imagens_FAA/Correlation.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#define dimensions of subplots (rows, columns)\n","fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","\n","#create chart in each subplot\n","sns.countplot(df_train, x=\"cat_CryoSleep\", hue=\"Transported\", ax=axes[1])\n","sns.countplot(df_train, x=\"SpendCategory\", hue=\"Transported\", ax=axes[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#define dimensions of subplots (rows, columns)\n","# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n","\n","#create chart in each subplot\n","sns.scatterplot(df_train, x=\"FoodCourt\", y=\"Spa\", hue=\"Transported\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import joblib\n","X_train, y_train = split_x_y(df_train)\n","X_test, y_test = split_x_y(df_test)\n","with open('data_FAA/data.pkl', 'wb') as f:\n","    joblib.dump([X_train, y_train, X_test, y_test], f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train[\"Transported\"]"]}],"metadata":{"kernelspec":{"display_name":"FAA","language":"python","name":"faa"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"7e7c335b56a27b5630f22c5ee38ba12dfcdb0b2b185351a846997b55ad4ddfd0"}}},"nbformat":4,"nbformat_minor":4}
