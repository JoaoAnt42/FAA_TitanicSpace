{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Keras with a date difference for the task loading\n",
    "Started on day Mon, 19 Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 11:18:43.623399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 641553\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle(\"./data/nc_tasks.pkl\")\n",
    "\n",
    "reviews = dataset[\"text\"].to_numpy()\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "print(\"Total examples:\", reviews.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 11:18:57.207613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training set size: 30000\n",
      "Validation set size: 10000\n",
      "Testing set size: 10000\n",
      "Unlabeled negative pool: 11384\n",
      "Unlabeled positive pool: 580169\n"
     ]
    }
   ],
   "source": [
    "val_split = 5000\n",
    "test_split = 5000\n",
    "train_split = 15000\n",
    "\n",
    "# Separating the negative and positive samples for manual stratification\n",
    "x_positives, y_positives = reviews[labels == 1], labels[labels == 1]\n",
    "x_negatives, y_negatives = reviews[labels == 0], labels[labels == 0]\n",
    "\n",
    "# Creating training, validation and testing splits\n",
    "x_val, y_val = (\n",
    "    tf.concat((x_positives[:val_split], x_negatives[:val_split]), 0),\n",
    "    tf.concat((y_positives[:val_split], y_negatives[:val_split]), 0),\n",
    ")\n",
    "x_test, y_test = (\n",
    "    tf.concat(\n",
    "        (\n",
    "            x_positives[val_split : val_split + test_split],\n",
    "            x_negatives[val_split : val_split + test_split],\n",
    "        ),\n",
    "        0,\n",
    "    ),\n",
    "    tf.concat(\n",
    "        (\n",
    "            y_positives[val_split : val_split + test_split],\n",
    "            y_negatives[val_split : val_split + test_split],\n",
    "        ),\n",
    "        0,\n",
    "    ),\n",
    ")\n",
    "x_train, y_train = (\n",
    "    tf.concat(\n",
    "        (\n",
    "            x_positives[val_split + test_split : val_split + test_split + train_split],\n",
    "            x_negatives[val_split + test_split : val_split + test_split + train_split],\n",
    "        ),\n",
    "        0,\n",
    "    ),\n",
    "    tf.concat(\n",
    "        (\n",
    "            y_positives[val_split + test_split : val_split + test_split + train_split],\n",
    "            y_negatives[val_split + test_split : val_split + test_split + train_split],\n",
    "        ),\n",
    "        0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Remaining pool of samples are stored separately. These are only labeled as and when required\n",
    "x_pool_positives, y_pool_positives = (\n",
    "    x_positives[val_split + test_split + train_split :],\n",
    "    y_positives[val_split + test_split + train_split :],\n",
    ")\n",
    "x_pool_negatives, y_pool_negatives = (\n",
    "    x_negatives[val_split + test_split + train_split :],\n",
    "    y_negatives[val_split + test_split + train_split :],\n",
    ")\n",
    "\n",
    "# Creating TF Datasets for faster prefetching and parallelization\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "pool_negatives = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_pool_negatives, y_pool_negatives)\n",
    ")\n",
    "pool_positives = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_pool_positives, y_pool_positives)\n",
    ")\n",
    "\n",
    "print(f\"Initial training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Testing set size: {len(test_dataset)}\")\n",
    "print(f\"Unlabeled negative pool: {len(pool_negatives)}\")\n",
    "print(f\"Unlabeled positive pool: {len(pool_positives)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joaoantonio/Documents/TTR/news_cruncher_ml/env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    30000, standardize=custom_standardization, output_sequence_length=150\n",
    ")\n",
    "# Adapting the dataset\n",
    "vectorizer.adapt(\n",
    "    train_dataset.map(lambda x, y: x, num_parallel_calls=tf.data.AUTOTUNE).batch(256)\n",
    ")\n",
    "\n",
    "\n",
    "def vectorize_text(text, label):\n",
    "    text = vectorizer(text)\n",
    "    return text, label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    vectorize_text, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "pool_negatives = pool_negatives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "pool_positives = pool_positives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(256).map(\n",
    "    vectorize_text, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "test_dataset = test_dataset.batch(256).map(\n",
    "    vectorize_text, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for merging new history objects with older ones\n",
    "def append_history(losses, val_losses, accuracy, val_accuracy, history):\n",
    "    losses = losses + history.history[\"loss\"]\n",
    "    val_losses = val_losses + history.history[\"val_loss\"]\n",
    "    accuracy = accuracy + history.history[\"binary_accuracy\"]\n",
    "    val_accuracy = val_accuracy + history.history[\"val_binary_accuracy\"]\n",
    "    return losses, val_losses, accuracy, val_accuracy\n",
    "\n",
    "\n",
    "# Plotter function\n",
    "def plot_history(losses, val_losses, accuracies, val_accuracies, optimizer):\n",
    "    plt.plot(losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"train_loss\", \"val_loss\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(f\"model/active/{optimizer}_loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(f\"model/active/{optimizer}_accuracy\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(150,)),\n",
    "            layers.Embedding(input_dim=30000, output_dim=128),\n",
    "            layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n",
    "            layers.GlobalMaxPool1D(),\n",
    "            layers.Dense(20, activation=\"relu\"),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_active_learning_models(\n",
    "    train_dataset,\n",
    "    pool_negatives,\n",
    "    pool_positives,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    "    optimizer,\n",
    "    num_iterations=5,\n",
    "    sampling_size=10000,\n",
    "):\n",
    "\n",
    "    # Creating lists for storing metrics\n",
    "    losses, val_losses, accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "    model = create_model()\n",
    "    # We will monitor the false positives and false negatives predicted by our model\n",
    "    # These will decide the subsequent sampling ratio for every Active Learning loop\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(),\n",
    "            keras.metrics.FalseNegatives(),\n",
    "            keras.metrics.FalsePositives(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Defining checkpoints.\n",
    "    # The checkpoint callback is reused throughout the training since it only saves the best overall model.\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        f\"model/active/{optimizer}_Model.h5\", save_best_only=True, verbose=1\n",
    "    )\n",
    "    # Here, patience is set to 4. This can be set higher if desired.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=4, verbose=1)\n",
    "\n",
    "    print(f\"Starting to train with {len(train_dataset)} samples\")\n",
    "    # Initial fit with a small subset of the training set\n",
    "    history = model.fit(\n",
    "        train_dataset.cache().shuffle(20000).batch(256),\n",
    "        epochs=40,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "    )\n",
    "\n",
    "    # Appending history\n",
    "    losses, val_losses, accuracies, val_accuracies = append_history(\n",
    "        losses, val_losses, accuracies, val_accuracies, history\n",
    "    )\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Getting predictions from previously trained model\n",
    "        predictions = model.predict(test_dataset)\n",
    "\n",
    "        # Generating labels from the output probabilities\n",
    "        rounded = tf.where(tf.greater(predictions, 0.5), 1, 0)\n",
    "\n",
    "        # Evaluating the number of zeros and ones incorrrectly classified\n",
    "        _, _, false_negatives, false_positives = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "        print(\"-\" * 100)\n",
    "        print(\n",
    "            f\"Number of zeros incorrectly classified: {false_negatives}, Number of ones incorrectly classified: {false_positives}\"\n",
    "        )\n",
    "\n",
    "        # This technique of Active Learning demonstrates ratio based sampling where\n",
    "        # Number of ones/zeros to sample = Number of ones/zeros incorrectly classified / Total incorrectly classified\n",
    "        if false_negatives != 0 and false_positives != 0:\n",
    "            total = false_negatives + false_positives\n",
    "            sample_ratio_ones, sample_ratio_zeros = (\n",
    "                false_positives / total,\n",
    "                false_negatives / total,\n",
    "            )\n",
    "        # In the case where all samples are correctly predicted, we can sample both classes equally\n",
    "        else:\n",
    "            sample_ratio_ones, sample_ratio_zeros = 0.5, 0.5\n",
    "\n",
    "        print(\n",
    "            f\"Sample ratio for positives: {sample_ratio_ones}, Sample ratio for negatives:{sample_ratio_zeros}\"\n",
    "        )\n",
    "\n",
    "        # Sample the required number of ones and zeros\n",
    "        sampled_dataset = pool_negatives.take(\n",
    "            int(sample_ratio_zeros * sampling_size)\n",
    "        ).concatenate(pool_positives.take(int(sample_ratio_ones * sampling_size)))\n",
    "\n",
    "        # Skip the sampled data points to avoid repetition of sample\n",
    "        pool_negatives = pool_negatives.skip(int(sample_ratio_zeros * sampling_size))\n",
    "        pool_positives = pool_positives.skip(int(sample_ratio_ones * sampling_size))\n",
    "\n",
    "        # Concatenating the train_dataset with the sampled_dataset\n",
    "        train_dataset = train_dataset.concatenate(sampled_dataset).prefetch(\n",
    "            tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "        print(f\"Starting training with {len(train_dataset)} samples\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        # We recompile the model to reset the optimizer states and retrain the model\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\n",
    "                keras.metrics.BinaryAccuracy(),\n",
    "                keras.metrics.FalseNegatives(),\n",
    "                keras.metrics.FalsePositives(),\n",
    "            ],\n",
    "        )\n",
    "        history = model.fit(\n",
    "            train_dataset.cache().shuffle(20000).batch(256),\n",
    "            validation_data=val_dataset,\n",
    "            epochs=40,\n",
    "            callbacks=[\n",
    "                checkpoint,\n",
    "                keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Appending the history\n",
    "        losses, val_losses, accuracies, val_accuracies = append_history(\n",
    "            losses, val_losses, accuracies, val_accuracies, history\n",
    "        )\n",
    "\n",
    "        # Loading the best model from this training loop\n",
    "        model = keras.models.load_model(f\"model/active/{optimizer}_Model.h5\")\n",
    "\n",
    "    # Plotting the overall history and evaluating the final model\n",
    "    plot_history(losses, val_losses, accuracies, val_accuracies, optimizer)\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Test set evaluation: \",\n",
    "        model.evaluate(test_dataset, verbose=0, return_dict=True),\n",
    "    )\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    return model, model.evaluate(test_dataset, verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 128)          3840000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 150, 64)          41216     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1300      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,882,537\n",
      "Trainable params: 3,882,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting to train with 30000 samples\n",
      "Epoch 1/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6939 - binary_accuracy: 0.5049 - false_negatives: 12609.0000 - false_positives: 2244.0000\n",
      "Epoch 1: val_loss improved from inf to 0.69353, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 47s 352ms/step - loss: 0.6939 - binary_accuracy: 0.5049 - false_negatives: 12609.0000 - false_positives: 2244.0000 - val_loss: 0.6935 - val_binary_accuracy: 0.5005 - val_false_negatives: 4988.0000 - val_false_positives: 7.0000\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5089 - false_negatives: 12597.0000 - false_positives: 2135.0000\n",
      "Epoch 2: val_loss improved from 0.69353 to 0.69350, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 47s 399ms/step - loss: 0.6933 - binary_accuracy: 0.5089 - false_negatives: 12597.0000 - false_positives: 2135.0000 - val_loss: 0.6935 - val_binary_accuracy: 0.5005 - val_false_negatives: 4988.0000 - val_false_positives: 7.0000\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6934 - binary_accuracy: 0.5111 - false_negatives: 12555.0000 - false_positives: 2112.0000\n",
      "Epoch 3: val_loss improved from 0.69350 to 0.69346, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 44s 369ms/step - loss: 0.6934 - binary_accuracy: 0.5111 - false_negatives: 12555.0000 - false_positives: 2112.0000 - val_loss: 0.6935 - val_binary_accuracy: 0.5006 - val_false_negatives: 4987.0000 - val_false_positives: 7.0000\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6937 - binary_accuracy: 0.5071 - false_negatives: 12605.0000 - false_positives: 2182.0000\n",
      "Epoch 4: val_loss improved from 0.69346 to 0.69342, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 46s 391ms/step - loss: 0.6937 - binary_accuracy: 0.5071 - false_negatives: 12605.0000 - false_positives: 2182.0000 - val_loss: 0.6934 - val_binary_accuracy: 0.5006 - val_false_negatives: 4987.0000 - val_false_positives: 7.0000\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6937 - binary_accuracy: 0.5080 - false_negatives: 12595.0000 - false_positives: 2166.0000\n",
      "Epoch 5: val_loss improved from 0.69342 to 0.69338, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 45s 383ms/step - loss: 0.6937 - binary_accuracy: 0.5080 - false_negatives: 12595.0000 - false_positives: 2166.0000 - val_loss: 0.6934 - val_binary_accuracy: 0.5007 - val_false_negatives: 4986.0000 - val_false_positives: 7.0000\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6936 - binary_accuracy: 0.5080 - false_negatives: 12544.0000 - false_positives: 2216.0000\n",
      "Epoch 6: val_loss improved from 0.69338 to 0.69334, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 45s 383ms/step - loss: 0.6936 - binary_accuracy: 0.5080 - false_negatives: 12544.0000 - false_positives: 2216.0000 - val_loss: 0.6933 - val_binary_accuracy: 0.5007 - val_false_negatives: 4986.0000 - val_false_positives: 7.0000\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6936 - binary_accuracy: 0.5077 - false_negatives: 12556.0000 - false_positives: 2213.0000\n",
      "Epoch 7: val_loss improved from 0.69334 to 0.69330, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 53s 450ms/step - loss: 0.6936 - binary_accuracy: 0.5077 - false_negatives: 12556.0000 - false_positives: 2213.0000 - val_loss: 0.6933 - val_binary_accuracy: 0.5009 - val_false_negatives: 4984.0000 - val_false_positives: 7.0000\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6935 - binary_accuracy: 0.5098 - false_negatives: 12525.0000 - false_positives: 2181.0000\n",
      "Epoch 8: val_loss improved from 0.69330 to 0.69326, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 45s 384ms/step - loss: 0.6935 - binary_accuracy: 0.5098 - false_negatives: 12525.0000 - false_positives: 2181.0000 - val_loss: 0.6933 - val_binary_accuracy: 0.5009 - val_false_negatives: 4982.0000 - val_false_positives: 9.0000\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6934 - binary_accuracy: 0.5065 - false_negatives: 12591.0000 - false_positives: 2213.0000\n",
      "Epoch 9: val_loss improved from 0.69326 to 0.69322, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 42s 356ms/step - loss: 0.6934 - binary_accuracy: 0.5065 - false_negatives: 12591.0000 - false_positives: 2213.0000 - val_loss: 0.6932 - val_binary_accuracy: 0.5011 - val_false_negatives: 4979.0000 - val_false_positives: 10.0000\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6935 - binary_accuracy: 0.5079 - false_negatives: 12595.0000 - false_positives: 2168.0000\n",
      "Epoch 10: val_loss improved from 0.69322 to 0.69318, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 47s 395ms/step - loss: 0.6935 - binary_accuracy: 0.5079 - false_negatives: 12595.0000 - false_positives: 2168.0000 - val_loss: 0.6932 - val_binary_accuracy: 0.5015 - val_false_negatives: 4975.0000 - val_false_positives: 10.0000\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5118 - false_negatives: 12483.0000 - false_positives: 2164.0000\n",
      "Epoch 11: val_loss improved from 0.69318 to 0.69314, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 41s 350ms/step - loss: 0.6933 - binary_accuracy: 0.5118 - false_negatives: 12483.0000 - false_positives: 2164.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5020 - val_false_negatives: 4970.0000 - val_false_positives: 10.0000\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6935 - binary_accuracy: 0.5108 - false_negatives: 12513.0000 - false_positives: 2162.0000\n",
      "Epoch 12: val_loss improved from 0.69314 to 0.69310, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 42s 352ms/step - loss: 0.6935 - binary_accuracy: 0.5108 - false_negatives: 12513.0000 - false_positives: 2162.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5025 - val_false_negatives: 4965.0000 - val_false_positives: 10.0000\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5119 - false_negatives: 12435.0000 - false_positives: 2209.0000\n",
      "Epoch 13: val_loss improved from 0.69310 to 0.69307, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 41s 351ms/step - loss: 0.6931 - binary_accuracy: 0.5119 - false_negatives: 12435.0000 - false_positives: 2209.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.4928 - val_false_negatives: 4956.0000 - val_false_positives: 116.0000\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6933 - binary_accuracy: 0.5111 - false_negatives: 12459.0000 - false_positives: 2208.0000\n",
      "Epoch 14: val_loss improved from 0.69307 to 0.69303, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 40s 339ms/step - loss: 0.6933 - binary_accuracy: 0.5111 - false_negatives: 12459.0000 - false_positives: 2208.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.4932 - val_false_negatives: 4951.0000 - val_false_positives: 117.0000\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5092 - false_negatives: 12526.0000 - false_positives: 2197.0000\n",
      "Epoch 15: val_loss improved from 0.69303 to 0.69299, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.6932 - binary_accuracy: 0.5092 - false_negatives: 12526.0000 - false_positives: 2197.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.4941 - val_false_negatives: 4941.0000 - val_false_positives: 118.0000\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6929 - binary_accuracy: 0.5127 - false_negatives: 12377.0000 - false_positives: 2241.0000\n",
      "Epoch 16: val_loss improved from 0.69299 to 0.69295, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.6929 - binary_accuracy: 0.5127 - false_negatives: 12377.0000 - false_positives: 2241.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.4947 - val_false_negatives: 4933.0000 - val_false_positives: 120.0000\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6927 - binary_accuracy: 0.5130 - false_negatives: 12363.0000 - false_positives: 2248.0000\n",
      "Epoch 17: val_loss improved from 0.69295 to 0.69292, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 49s 417ms/step - loss: 0.6927 - binary_accuracy: 0.5130 - false_negatives: 12363.0000 - false_positives: 2248.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.4963 - val_false_negatives: 4914.0000 - val_false_positives: 123.0000\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.5130 - false_negatives: 12347.0000 - false_positives: 2262.0000\n",
      "Epoch 18: val_loss improved from 0.69292 to 0.69288, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 49s 415ms/step - loss: 0.6931 - binary_accuracy: 0.5130 - false_negatives: 12347.0000 - false_positives: 2262.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.4973 - val_false_negatives: 4902.0000 - val_false_positives: 125.0000\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5186 - false_negatives: 12294.0000 - false_positives: 2149.0000\n",
      "Epoch 19: val_loss improved from 0.69288 to 0.69284, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 55s 470ms/step - loss: 0.6925 - binary_accuracy: 0.5186 - false_negatives: 12294.0000 - false_positives: 2149.0000 - val_loss: 0.6928 - val_binary_accuracy: 0.4980 - val_false_negatives: 4889.0000 - val_false_positives: 131.0000\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6929 - binary_accuracy: 0.5124 - false_negatives: 12327.0000 - false_positives: 2301.0000\n",
      "Epoch 20: val_loss improved from 0.69284 to 0.69281, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 54s 454ms/step - loss: 0.6929 - binary_accuracy: 0.5124 - false_negatives: 12327.0000 - false_positives: 2301.0000 - val_loss: 0.6928 - val_binary_accuracy: 0.4997 - val_false_negatives: 4871.0000 - val_false_positives: 132.0000\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6926 - binary_accuracy: 0.5150 - false_negatives: 12332.0000 - false_positives: 2217.0000\n",
      "Epoch 21: val_loss improved from 0.69281 to 0.69277, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 49s 417ms/step - loss: 0.6926 - binary_accuracy: 0.5150 - false_negatives: 12332.0000 - false_positives: 2217.0000 - val_loss: 0.6928 - val_binary_accuracy: 0.5011 - val_false_negatives: 4853.0000 - val_false_positives: 136.0000\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5124 - false_negatives: 12382.0000 - false_positives: 2247.0000\n",
      "Epoch 22: val_loss improved from 0.69277 to 0.69273, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 42s 358ms/step - loss: 0.6925 - binary_accuracy: 0.5124 - false_negatives: 12382.0000 - false_positives: 2247.0000 - val_loss: 0.6927 - val_binary_accuracy: 0.5028 - val_false_negatives: 4827.0000 - val_false_positives: 145.0000\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6926 - binary_accuracy: 0.5168 - false_negatives: 12292.0000 - false_positives: 2205.0000\n",
      "Epoch 23: val_loss improved from 0.69273 to 0.69269, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 44s 370ms/step - loss: 0.6926 - binary_accuracy: 0.5168 - false_negatives: 12292.0000 - false_positives: 2205.0000 - val_loss: 0.6927 - val_binary_accuracy: 0.5045 - val_false_negatives: 4806.0000 - val_false_positives: 149.0000\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6927 - binary_accuracy: 0.5169 - false_negatives: 12270.0000 - false_positives: 2223.0000\n",
      "Epoch 24: val_loss improved from 0.69269 to 0.69266, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 53s 448ms/step - loss: 0.6927 - binary_accuracy: 0.5169 - false_negatives: 12270.0000 - false_positives: 2223.0000 - val_loss: 0.6927 - val_binary_accuracy: 0.5068 - val_false_negatives: 4777.0000 - val_false_positives: 155.0000\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6926 - binary_accuracy: 0.5146 - false_negatives: 12353.0000 - false_positives: 2208.0000\n",
      "Epoch 25: val_loss improved from 0.69266 to 0.69262, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 45s 382ms/step - loss: 0.6926 - binary_accuracy: 0.5146 - false_negatives: 12353.0000 - false_positives: 2208.0000 - val_loss: 0.6926 - val_binary_accuracy: 0.5083 - val_false_negatives: 4754.0000 - val_false_positives: 163.0000\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6926 - binary_accuracy: 0.5166 - false_negatives: 12301.0000 - false_positives: 2202.0000\n",
      "Epoch 26: val_loss improved from 0.69262 to 0.69258, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 60s 511ms/step - loss: 0.6926 - binary_accuracy: 0.5166 - false_negatives: 12301.0000 - false_positives: 2202.0000 - val_loss: 0.6926 - val_binary_accuracy: 0.5106 - val_false_negatives: 4719.0000 - val_false_positives: 175.0000\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6927 - binary_accuracy: 0.5163 - false_negatives: 12334.0000 - false_positives: 2176.0000\n",
      "Epoch 27: val_loss improved from 0.69258 to 0.69254, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 62s 528ms/step - loss: 0.6927 - binary_accuracy: 0.5163 - false_negatives: 12334.0000 - false_positives: 2176.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.5125 - val_false_negatives: 4692.0000 - val_false_positives: 183.0000\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6929 - binary_accuracy: 0.5187 - false_negatives: 12270.0000 - false_positives: 2169.0000\n",
      "Epoch 28: val_loss improved from 0.69254 to 0.69250, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 58s 494ms/step - loss: 0.6929 - binary_accuracy: 0.5187 - false_negatives: 12270.0000 - false_positives: 2169.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.5147 - val_false_negatives: 4659.0000 - val_false_positives: 194.0000\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5181 - false_negatives: 12250.0000 - false_positives: 2206.0000\n",
      "Epoch 29: val_loss improved from 0.69250 to 0.69247, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 58s 487ms/step - loss: 0.6925 - binary_accuracy: 0.5181 - false_negatives: 12250.0000 - false_positives: 2206.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.5179 - val_false_negatives: 4620.0000 - val_false_positives: 201.0000\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5135 - false_negatives: 12289.0000 - false_positives: 2307.0000\n",
      "Epoch 30: val_loss improved from 0.69247 to 0.69243, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 49s 415ms/step - loss: 0.6925 - binary_accuracy: 0.5135 - false_negatives: 12289.0000 - false_positives: 2307.0000 - val_loss: 0.6924 - val_binary_accuracy: 0.5207 - val_false_negatives: 4582.0000 - val_false_positives: 211.0000\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6922 - binary_accuracy: 0.5187 - false_negatives: 12208.0000 - false_positives: 2232.0000\n",
      "Epoch 31: val_loss improved from 0.69243 to 0.69238, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 46s 390ms/step - loss: 0.6922 - binary_accuracy: 0.5187 - false_negatives: 12208.0000 - false_positives: 2232.0000 - val_loss: 0.6924 - val_binary_accuracy: 0.5233 - val_false_negatives: 4542.0000 - val_false_positives: 225.0000\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6923 - binary_accuracy: 0.5238 - false_negatives: 12095.0000 - false_positives: 2191.0000\n",
      "Epoch 32: val_loss improved from 0.69238 to 0.69234, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 46s 391ms/step - loss: 0.6923 - binary_accuracy: 0.5238 - false_negatives: 12095.0000 - false_positives: 2191.0000 - val_loss: 0.6923 - val_binary_accuracy: 0.5249 - val_false_negatives: 4506.0000 - val_false_positives: 245.0000\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5208 - false_negatives: 12118.0000 - false_positives: 2259.0000\n",
      "Epoch 33: val_loss improved from 0.69234 to 0.69230, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 44s 376ms/step - loss: 0.6925 - binary_accuracy: 0.5208 - false_negatives: 12118.0000 - false_positives: 2259.0000 - val_loss: 0.6923 - val_binary_accuracy: 0.5274 - val_false_negatives: 4461.0000 - val_false_positives: 265.0000\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6920 - binary_accuracy: 0.5207 - false_negatives: 12197.0000 - false_positives: 2182.0000\n",
      "Epoch 34: val_loss improved from 0.69230 to 0.69226, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 44s 376ms/step - loss: 0.6920 - binary_accuracy: 0.5207 - false_negatives: 12197.0000 - false_positives: 2182.0000 - val_loss: 0.6923 - val_binary_accuracy: 0.5295 - val_false_negatives: 4423.0000 - val_false_positives: 282.0000\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6920 - binary_accuracy: 0.5230 - false_negatives: 12111.0000 - false_positives: 2198.0000\n",
      "Epoch 35: val_loss improved from 0.69226 to 0.69221, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 48s 405ms/step - loss: 0.6920 - binary_accuracy: 0.5230 - false_negatives: 12111.0000 - false_positives: 2198.0000 - val_loss: 0.6922 - val_binary_accuracy: 0.5318 - val_false_negatives: 4379.0000 - val_false_positives: 303.0000\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6920 - binary_accuracy: 0.5242 - false_negatives: 12015.0000 - false_positives: 2260.0000\n",
      "Epoch 36: val_loss improved from 0.69221 to 0.69217, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 52s 442ms/step - loss: 0.6920 - binary_accuracy: 0.5242 - false_negatives: 12015.0000 - false_positives: 2260.0000 - val_loss: 0.6922 - val_binary_accuracy: 0.5345 - val_false_negatives: 4337.0000 - val_false_positives: 318.0000\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6921 - binary_accuracy: 0.5215 - false_negatives: 12074.0000 - false_positives: 2282.0000\n",
      "Epoch 37: val_loss improved from 0.69217 to 0.69212, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 43s 363ms/step - loss: 0.6921 - binary_accuracy: 0.5215 - false_negatives: 12074.0000 - false_positives: 2282.0000 - val_loss: 0.6921 - val_binary_accuracy: 0.5372 - val_false_negatives: 4282.0000 - val_false_positives: 346.0000\n",
      "Epoch 38/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6919 - binary_accuracy: 0.5257 - false_negatives: 11961.0000 - false_positives: 2268.0000\n",
      "Epoch 38: val_loss improved from 0.69212 to 0.69207, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 46s 388ms/step - loss: 0.6919 - binary_accuracy: 0.5257 - false_negatives: 11961.0000 - false_positives: 2268.0000 - val_loss: 0.6921 - val_binary_accuracy: 0.5399 - val_false_negatives: 4229.0000 - val_false_positives: 372.0000\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6923 - binary_accuracy: 0.5247 - false_negatives: 11906.0000 - false_positives: 2354.0000\n",
      "Epoch 39: val_loss improved from 0.69207 to 0.69202, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 41s 350ms/step - loss: 0.6923 - binary_accuracy: 0.5247 - false_negatives: 11906.0000 - false_positives: 2354.0000 - val_loss: 0.6920 - val_binary_accuracy: 0.5432 - val_false_negatives: 4166.0000 - val_false_positives: 402.0000\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6923 - binary_accuracy: 0.5239 - false_negatives: 11997.0000 - false_positives: 2287.0000\n",
      "Epoch 40: val_loss improved from 0.69202 to 0.69197, saving model to model/active/Adadelta_Model.h5\n",
      "118/118 [==============================] - 44s 376ms/step - loss: 0.6923 - binary_accuracy: 0.5239 - false_negatives: 11997.0000 - false_positives: 2287.0000 - val_loss: 0.6920 - val_binary_accuracy: 0.5452 - val_false_negatives: 4111.0000 - val_false_positives: 437.0000\n",
      "40/40 [==============================] - 6s 119ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 3977.0, Number of ones incorrectly classified: 290.0\n",
      "Sample ratio for positives: 0.06796344035622218, Sample ratio for negatives:0.9320365596437779\n",
      "Starting training with 39999 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6848 - binary_accuracy: 0.6079 - false_negatives_1: 12462.0000 - false_positives_1: 3221.0000\n",
      "Epoch 1: val_loss improved from 0.69197 to 0.69194, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 68s 404ms/step - loss: 0.6848 - binary_accuracy: 0.6079 - false_negatives_1: 12462.0000 - false_positives_1: 3221.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.5446 - val_false_negatives_1: 4151.0000 - val_false_positives_1: 403.0000\n",
      "Epoch 2/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6842 - binary_accuracy: 0.6077 - false_negatives_1: 12572.0000 - false_positives_1: 3120.0000\n",
      "Epoch 2: val_loss improved from 0.69194 to 0.69190, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 59s 374ms/step - loss: 0.6842 - binary_accuracy: 0.6077 - false_negatives_1: 12572.0000 - false_positives_1: 3120.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.5425 - val_false_negatives_1: 4208.0000 - val_false_positives_1: 367.0000\n",
      "Epoch 3/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6840 - binary_accuracy: 0.6099 - false_negatives_1: 12795.0000 - false_positives_1: 2808.0000\n",
      "Epoch 3: val_loss improved from 0.69190 to 0.69186, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 58s 371ms/step - loss: 0.6840 - binary_accuracy: 0.6099 - false_negatives_1: 12795.0000 - false_positives_1: 2808.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.5423 - val_false_negatives_1: 4260.0000 - val_false_positives_1: 317.0000\n",
      "Epoch 4/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6834 - binary_accuracy: 0.6109 - false_negatives_1: 12939.0000 - false_positives_1: 2623.0000\n",
      "Epoch 4: val_loss improved from 0.69186 to 0.69183, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 58s 366ms/step - loss: 0.6834 - binary_accuracy: 0.6109 - false_negatives_1: 12939.0000 - false_positives_1: 2623.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5402 - val_false_negatives_1: 4301.0000 - val_false_positives_1: 297.0000\n",
      "Epoch 5/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6832 - binary_accuracy: 0.6115 - false_negatives_1: 13132.0000 - false_positives_1: 2409.0000\n",
      "Epoch 5: val_loss improved from 0.69183 to 0.69180, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 58s 370ms/step - loss: 0.6832 - binary_accuracy: 0.6115 - false_negatives_1: 13132.0000 - false_positives_1: 2409.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5372 - val_false_negatives_1: 4351.0000 - val_false_positives_1: 277.0000\n",
      "Epoch 6/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6824 - binary_accuracy: 0.6146 - false_negatives_1: 13213.0000 - false_positives_1: 2203.0000\n",
      "Epoch 6: val_loss improved from 0.69180 to 0.69177, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.6824 - binary_accuracy: 0.6146 - false_negatives_1: 13213.0000 - false_positives_1: 2203.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5355 - val_false_negatives_1: 4402.0000 - val_false_positives_1: 243.0000\n",
      "Epoch 7/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6825 - binary_accuracy: 0.6165 - false_negatives_1: 13400.0000 - false_positives_1: 1939.0000\n",
      "Epoch 7: val_loss improved from 0.69177 to 0.69175, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 66s 418ms/step - loss: 0.6825 - binary_accuracy: 0.6165 - false_negatives_1: 13400.0000 - false_positives_1: 1939.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5327 - val_false_negatives_1: 4454.0000 - val_false_positives_1: 219.0000\n",
      "Epoch 8/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6821 - binary_accuracy: 0.6151 - false_negatives_1: 13494.0000 - false_positives_1: 1901.0000\n",
      "Epoch 8: val_loss improved from 0.69175 to 0.69173, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 59s 376ms/step - loss: 0.6821 - binary_accuracy: 0.6151 - false_negatives_1: 13494.0000 - false_positives_1: 1901.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5286 - val_false_negatives_1: 4508.0000 - val_false_positives_1: 206.0000\n",
      "Epoch 9/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6816 - binary_accuracy: 0.6142 - false_negatives_1: 13690.0000 - false_positives_1: 1742.0000\n",
      "Epoch 9: val_loss improved from 0.69173 to 0.69172, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 61s 389ms/step - loss: 0.6816 - binary_accuracy: 0.6142 - false_negatives_1: 13690.0000 - false_positives_1: 1742.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5267 - val_false_negatives_1: 4548.0000 - val_false_positives_1: 185.0000\n",
      "Epoch 10/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6815 - binary_accuracy: 0.6155 - false_negatives_1: 13750.0000 - false_positives_1: 1629.0000\n",
      "Epoch 10: val_loss improved from 0.69172 to 0.69171, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 57s 364ms/step - loss: 0.6815 - binary_accuracy: 0.6155 - false_negatives_1: 13750.0000 - false_positives_1: 1629.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5249 - val_false_negatives_1: 4580.0000 - val_false_positives_1: 171.0000\n",
      "Epoch 11/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6810 - binary_accuracy: 0.6164 - false_negatives_1: 13888.0000 - false_positives_1: 1456.0000\n",
      "Epoch 11: val_loss improved from 0.69171 to 0.69170, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 60s 385ms/step - loss: 0.6810 - binary_accuracy: 0.6164 - false_negatives_1: 13888.0000 - false_positives_1: 1456.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5231 - val_false_negatives_1: 4608.0000 - val_false_positives_1: 161.0000\n",
      "Epoch 12/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6806 - binary_accuracy: 0.6170 - false_negatives_1: 14008.0000 - false_positives_1: 1311.0000\n",
      "Epoch 12: val_loss improved from 0.69170 to 0.69170, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 61s 389ms/step - loss: 0.6806 - binary_accuracy: 0.6170 - false_negatives_1: 14008.0000 - false_positives_1: 1311.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5196 - val_false_negatives_1: 4648.0000 - val_false_positives_1: 156.0000\n",
      "Epoch 13/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6800 - binary_accuracy: 0.6201 - false_negatives_1: 13994.0000 - false_positives_1: 1200.0000\n",
      "Epoch 13: val_loss improved from 0.69170 to 0.69170, saving model to model/active/Adadelta_Model.h5\n",
      "157/157 [==============================] - 56s 358ms/step - loss: 0.6800 - binary_accuracy: 0.6201 - false_negatives_1: 13994.0000 - false_positives_1: 1200.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5167 - val_false_negatives_1: 4681.0000 - val_false_positives_1: 152.0000\n",
      "Epoch 14/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6798 - binary_accuracy: 0.6187 - false_negatives_1: 14176.0000 - false_positives_1: 1075.0000\n",
      "Epoch 14: val_loss did not improve from 0.69170\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 0.6798 - binary_accuracy: 0.6187 - false_negatives_1: 14176.0000 - false_positives_1: 1075.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5125 - val_false_negatives_1: 4727.0000 - val_false_positives_1: 148.0000\n",
      "Epoch 15/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6793 - binary_accuracy: 0.6188 - false_negatives_1: 14202.0000 - false_positives_1: 1045.0000\n",
      "Epoch 15: val_loss did not improve from 0.69170\n",
      "157/157 [==============================] - 64s 407ms/step - loss: 0.6793 - binary_accuracy: 0.6188 - false_negatives_1: 14202.0000 - false_positives_1: 1045.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5105 - val_false_negatives_1: 4750.0000 - val_false_positives_1: 145.0000\n",
      "Epoch 16/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6788 - binary_accuracy: 0.6197 - false_negatives_1: 14297.0000 - false_positives_1: 914.0000\n",
      "Epoch 16: val_loss did not improve from 0.69170\n",
      "157/157 [==============================] - 57s 363ms/step - loss: 0.6788 - binary_accuracy: 0.6197 - false_negatives_1: 14297.0000 - false_positives_1: 914.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5074 - val_false_negatives_1: 4783.0000 - val_false_positives_1: 143.0000\n",
      "Epoch 17/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6787 - binary_accuracy: 0.6202 - false_negatives_1: 14375.0000 - false_positives_1: 817.0000\n",
      "Epoch 17: val_loss did not improve from 0.69170\n",
      "157/157 [==============================] - 67s 428ms/step - loss: 0.6787 - binary_accuracy: 0.6202 - false_negatives_1: 14375.0000 - false_positives_1: 817.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5051 - val_false_negatives_1: 4807.0000 - val_false_positives_1: 142.0000\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 5s 103ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 4670.0, Number of ones incorrectly classified: 50.0\n",
      "Sample ratio for positives: 0.01059322033898305, Sample ratio for negatives:0.989406779661017\n",
      "Starting training with 42168 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6782 - binary_accuracy: 0.6320 - false_negatives_2: 14260.0000 - false_positives_2: 1256.0000\n",
      "Epoch 1: val_loss did not improve from 0.69170\n",
      "165/165 [==============================] - 68s 385ms/step - loss: 0.6782 - binary_accuracy: 0.6320 - false_negatives_2: 14260.0000 - false_positives_2: 1256.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5124 - val_false_negatives_2: 4729.0000 - val_false_positives_2: 147.0000\n",
      "Epoch 2/40\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6779 - binary_accuracy: 0.6324 - false_negatives_2: 14314.0000 - false_positives_2: 1188.0000\n",
      "Epoch 2: val_loss did not improve from 0.69170\n",
      "165/165 [==============================] - 64s 388ms/step - loss: 0.6779 - binary_accuracy: 0.6324 - false_negatives_2: 14314.0000 - false_positives_2: 1188.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5099 - val_false_negatives_2: 4757.0000 - val_false_positives_2: 144.0000\n",
      "Epoch 3/40\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6775 - binary_accuracy: 0.6301 - false_negatives_2: 14451.0000 - false_positives_2: 1149.0000\n",
      "Epoch 3: val_loss did not improve from 0.69170\n",
      "165/165 [==============================] - 61s 370ms/step - loss: 0.6775 - binary_accuracy: 0.6301 - false_negatives_2: 14451.0000 - false_positives_2: 1149.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5063 - val_false_negatives_2: 4795.0000 - val_false_positives_2: 142.0000\n",
      "Epoch 4/40\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6769 - binary_accuracy: 0.6306 - false_negatives_2: 14547.0000 - false_positives_2: 1028.0000\n",
      "Epoch 4: val_loss did not improve from 0.69170\n",
      "165/165 [==============================] - 65s 393ms/step - loss: 0.6769 - binary_accuracy: 0.6306 - false_negatives_2: 14547.0000 - false_positives_2: 1028.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5039 - val_false_negatives_2: 4825.0000 - val_false_positives_2: 136.0000\n",
      "Epoch 5/40\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.6766 - binary_accuracy: 0.6324 - false_negatives_2: 14570.0000 - false_positives_2: 931.0000\n",
      "Epoch 5: val_loss did not improve from 0.69170\n",
      "165/165 [==============================] - 68s 415ms/step - loss: 0.6766 - binary_accuracy: 0.6324 - false_negatives_2: 14570.0000 - false_positives_2: 931.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5021 - val_false_negatives_2: 4847.0000 - val_false_positives_2: 132.0000\n",
      "Epoch 5: early stopping\n",
      "40/40 [==============================] - 7s 137ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 4670.0, Number of ones incorrectly classified: 50.0\n",
      "Sample ratio for positives: 0.01059322033898305, Sample ratio for negatives:0.989406779661017\n",
      "Starting training with 42273 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6789 - binary_accuracy: 0.6287 - false_negatives_3: 14395.0000 - false_positives_3: 1302.0000\n",
      "Epoch 1: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 68s 379ms/step - loss: 0.6789 - binary_accuracy: 0.6287 - false_negatives_3: 14395.0000 - false_positives_3: 1302.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5127 - val_false_negatives_3: 4725.0000 - val_false_positives_3: 148.0000\n",
      "Epoch 2/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6781 - binary_accuracy: 0.6291 - false_negatives_3: 14473.0000 - false_positives_3: 1208.0000\n",
      "Epoch 2: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 61s 367ms/step - loss: 0.6781 - binary_accuracy: 0.6291 - false_negatives_3: 14473.0000 - false_positives_3: 1208.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5097 - val_false_negatives_3: 4759.0000 - val_false_positives_3: 144.0000\n",
      "Epoch 3/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6779 - binary_accuracy: 0.6293 - false_negatives_3: 14527.0000 - false_positives_3: 1143.0000\n",
      "Epoch 3: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 63s 378ms/step - loss: 0.6779 - binary_accuracy: 0.6293 - false_negatives_3: 14527.0000 - false_positives_3: 1143.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5065 - val_false_negatives_3: 4793.0000 - val_false_positives_3: 142.0000\n",
      "Epoch 4/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6774 - binary_accuracy: 0.6288 - false_negatives_3: 14656.0000 - false_positives_3: 1035.0000\n",
      "Epoch 4: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 63s 379ms/step - loss: 0.6774 - binary_accuracy: 0.6288 - false_negatives_3: 14656.0000 - false_positives_3: 1035.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5041 - val_false_negatives_3: 4821.0000 - val_false_positives_3: 138.0000\n",
      "Epoch 5/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6772 - binary_accuracy: 0.6308 - false_negatives_3: 14694.0000 - false_positives_3: 914.0000\n",
      "Epoch 5: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 60s 363ms/step - loss: 0.6772 - binary_accuracy: 0.6308 - false_negatives_3: 14694.0000 - false_positives_3: 914.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5023 - val_false_negatives_3: 4845.0000 - val_false_positives_3: 132.0000\n",
      "Epoch 5: early stopping\n",
      "40/40 [==============================] - 5s 103ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 4670.0, Number of ones incorrectly classified: 50.0\n",
      "Sample ratio for positives: 0.01059322033898305, Sample ratio for negatives:0.989406779661017\n",
      "Starting training with 42378 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6786 - binary_accuracy: 0.6293 - false_negatives_4: 14369.0000 - false_positives_4: 1340.0000\n",
      "Epoch 1: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 66s 366ms/step - loss: 0.6786 - binary_accuracy: 0.6293 - false_negatives_4: 14369.0000 - false_positives_4: 1340.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5127 - val_false_negatives_4: 4725.0000 - val_false_positives_4: 148.0000\n",
      "Epoch 2/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6784 - binary_accuracy: 0.6306 - false_negatives_4: 14438.0000 - false_positives_4: 1218.0000\n",
      "Epoch 2: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 59s 354ms/step - loss: 0.6784 - binary_accuracy: 0.6306 - false_negatives_4: 14438.0000 - false_positives_4: 1218.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5100 - val_false_negatives_4: 4755.0000 - val_false_positives_4: 145.0000\n",
      "Epoch 3/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6783 - binary_accuracy: 0.6292 - false_negatives_4: 14566.0000 - false_positives_4: 1148.0000\n",
      "Epoch 3: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 60s 359ms/step - loss: 0.6783 - binary_accuracy: 0.6292 - false_negatives_4: 14566.0000 - false_positives_4: 1148.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5064 - val_false_negatives_4: 4793.0000 - val_false_positives_4: 143.0000\n",
      "Epoch 4/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6776 - binary_accuracy: 0.6301 - false_negatives_4: 14652.0000 - false_positives_4: 1025.0000\n",
      "Epoch 4: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 61s 365ms/step - loss: 0.6776 - binary_accuracy: 0.6301 - false_negatives_4: 14652.0000 - false_positives_4: 1025.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5045 - val_false_negatives_4: 4816.0000 - val_false_positives_4: 139.0000\n",
      "Epoch 5/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6774 - binary_accuracy: 0.6294 - false_negatives_4: 14763.0000 - false_positives_4: 942.0000\n",
      "Epoch 5: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 61s 364ms/step - loss: 0.6774 - binary_accuracy: 0.6294 - false_negatives_4: 14763.0000 - false_positives_4: 942.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5025 - val_false_negatives_4: 4843.0000 - val_false_positives_4: 132.0000\n",
      "Epoch 5: early stopping\n",
      "40/40 [==============================] - 5s 106ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 4670.0, Number of ones incorrectly classified: 50.0\n",
      "Sample ratio for positives: 0.01059322033898305, Sample ratio for negatives:0.989406779661017\n",
      "Starting training with 42483 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6790 - binary_accuracy: 0.6269 - false_negatives_5: 14479.0000 - false_positives_5: 1372.0000\n",
      "Epoch 1: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 67s 368ms/step - loss: 0.6790 - binary_accuracy: 0.6269 - false_negatives_5: 14479.0000 - false_positives_5: 1372.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5127 - val_false_negatives_5: 4724.0000 - val_false_positives_5: 149.0000\n",
      "Epoch 2/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6783 - binary_accuracy: 0.6283 - false_negatives_5: 14543.0000 - false_positives_5: 1247.0000\n",
      "Epoch 2: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 61s 365ms/step - loss: 0.6783 - binary_accuracy: 0.6283 - false_negatives_5: 14543.0000 - false_positives_5: 1247.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5099 - val_false_negatives_5: 4756.0000 - val_false_positives_5: 145.0000\n",
      "Epoch 3/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6779 - binary_accuracy: 0.6282 - false_negatives_5: 14665.0000 - false_positives_5: 1132.0000\n",
      "Epoch 3: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 60s 360ms/step - loss: 0.6779 - binary_accuracy: 0.6282 - false_negatives_5: 14665.0000 - false_positives_5: 1132.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5068 - val_false_negatives_5: 4789.0000 - val_false_positives_5: 143.0000\n",
      "Epoch 4/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6776 - binary_accuracy: 0.6282 - false_negatives_5: 14748.0000 - false_positives_5: 1048.0000\n",
      "Epoch 4: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 60s 358ms/step - loss: 0.6776 - binary_accuracy: 0.6282 - false_negatives_5: 14748.0000 - false_positives_5: 1048.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5045 - val_false_negatives_5: 4815.0000 - val_false_positives_5: 140.0000\n",
      "Epoch 5/40\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.6770 - binary_accuracy: 0.6292 - false_negatives_5: 14806.0000 - false_positives_5: 946.0000\n",
      "Epoch 5: val_loss did not improve from 0.69170\n",
      "166/166 [==============================] - 60s 363ms/step - loss: 0.6770 - binary_accuracy: 0.6292 - false_negatives_5: 14806.0000 - false_positives_5: 946.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.5026 - val_false_negatives_5: 4841.0000 - val_false_positives_5: 133.0000\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 0.6893324851989746, 'binary_accuracy': 0.527999997138977, 'false_negatives_1': 4670.0, 'false_positives_1': 50.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 128)          3840000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 150, 64)          41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,882,537\n",
      "Trainable params: 3,882,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting to train with 30000 samples\n",
      "Epoch 1/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6935 - binary_accuracy: 0.5045 - false_negatives_6: 3295.0000 - false_positives_6: 11571.0000\n",
      "Epoch 1: val_loss improved from inf to 0.69321, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 45s 334ms/step - loss: 0.6935 - binary_accuracy: 0.5045 - false_negatives_6: 3295.0000 - false_positives_6: 11571.0000 - val_loss: 0.6932 - val_binary_accuracy: 0.4979 - val_false_negatives_6: 231.0000 - val_false_positives_6: 4790.0000\n",
      "Epoch 2/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6930 - binary_accuracy: 0.5083 - false_negatives_6: 3823.0000 - false_positives_6: 10927.0000\n",
      "Epoch 2: val_loss improved from 0.69321 to 0.69293, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 328ms/step - loss: 0.6930 - binary_accuracy: 0.5083 - false_negatives_6: 3823.0000 - false_positives_6: 10927.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.5089 - val_false_negatives_6: 567.0000 - val_false_positives_6: 4344.0000\n",
      "Epoch 3/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6929 - binary_accuracy: 0.5093 - false_negatives_6: 4493.0000 - false_positives_6: 10228.0000\n",
      "Epoch 3: val_loss improved from 0.69293 to 0.69272, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 335ms/step - loss: 0.6929 - binary_accuracy: 0.5093 - false_negatives_6: 4493.0000 - false_positives_6: 10228.0000 - val_loss: 0.6927 - val_binary_accuracy: 0.5233 - val_false_negatives_6: 1286.0000 - val_false_positives_6: 3481.0000\n",
      "Epoch 4/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5191 - false_negatives_6: 4995.0000 - false_positives_6: 9431.0000\n",
      "Epoch 4: val_loss improved from 0.69272 to 0.69250, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 40s 341ms/step - loss: 0.6925 - binary_accuracy: 0.5191 - false_negatives_6: 4995.0000 - false_positives_6: 9431.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.5340 - val_false_negatives_6: 2139.0000 - val_false_positives_6: 2521.0000\n",
      "Epoch 5/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6925 - binary_accuracy: 0.5198 - false_negatives_6: 5883.0000 - false_positives_6: 8523.0000\n",
      "Epoch 5: val_loss improved from 0.69250 to 0.69231, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 326ms/step - loss: 0.6925 - binary_accuracy: 0.5198 - false_negatives_6: 5883.0000 - false_positives_6: 8523.0000 - val_loss: 0.6923 - val_binary_accuracy: 0.5378 - val_false_negatives_6: 2649.0000 - val_false_positives_6: 1973.0000\n",
      "Epoch 6/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6923 - binary_accuracy: 0.5219 - false_negatives_6: 6256.0000 - false_positives_6: 8088.0000\n",
      "Epoch 6: val_loss improved from 0.69231 to 0.69211, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 40s 336ms/step - loss: 0.6923 - binary_accuracy: 0.5219 - false_negatives_6: 6256.0000 - false_positives_6: 8088.0000 - val_loss: 0.6921 - val_binary_accuracy: 0.5380 - val_false_negatives_6: 2830.0000 - val_false_positives_6: 1790.0000\n",
      "Epoch 7/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6921 - binary_accuracy: 0.5234 - false_negatives_6: 7105.0000 - false_positives_6: 7192.0000\n",
      "Epoch 7: val_loss improved from 0.69211 to 0.69193, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 335ms/step - loss: 0.6921 - binary_accuracy: 0.5234 - false_negatives_6: 7105.0000 - false_positives_6: 7192.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.5358 - val_false_negatives_6: 2892.0000 - val_false_positives_6: 1750.0000\n",
      "Epoch 8/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6917 - binary_accuracy: 0.5338 - false_negatives_6: 7527.0000 - false_positives_6: 6459.0000\n",
      "Epoch 8: val_loss improved from 0.69193 to 0.69174, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 37s 316ms/step - loss: 0.6917 - binary_accuracy: 0.5338 - false_negatives_6: 7527.0000 - false_positives_6: 6459.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.5349 - val_false_negatives_6: 2927.0000 - val_false_positives_6: 1724.0000\n",
      "Epoch 9/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6915 - binary_accuracy: 0.5345 - false_negatives_6: 7745.0000 - false_positives_6: 6221.0000\n",
      "Epoch 9: val_loss improved from 0.69174 to 0.69156, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.6915 - binary_accuracy: 0.5345 - false_negatives_6: 7745.0000 - false_positives_6: 6221.0000 - val_loss: 0.6916 - val_binary_accuracy: 0.5355 - val_false_negatives_6: 2939.0000 - val_false_positives_6: 1706.0000\n",
      "Epoch 10/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6914 - binary_accuracy: 0.5355 - false_negatives_6: 8308.0000 - false_positives_6: 5627.0000\n",
      "Epoch 10: val_loss improved from 0.69156 to 0.69139, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 329ms/step - loss: 0.6914 - binary_accuracy: 0.5355 - false_negatives_6: 8308.0000 - false_positives_6: 5627.0000 - val_loss: 0.6914 - val_binary_accuracy: 0.5351 - val_false_negatives_6: 2939.0000 - val_false_positives_6: 1710.0000\n",
      "Epoch 11/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6913 - binary_accuracy: 0.5403 - false_negatives_6: 8408.0000 - false_positives_6: 5382.0000\n",
      "Epoch 11: val_loss improved from 0.69139 to 0.69122, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 37s 317ms/step - loss: 0.6913 - binary_accuracy: 0.5403 - false_negatives_6: 8408.0000 - false_positives_6: 5382.0000 - val_loss: 0.6912 - val_binary_accuracy: 0.5346 - val_false_negatives_6: 2939.0000 - val_false_positives_6: 1715.0000\n",
      "Epoch 12/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6912 - binary_accuracy: 0.5368 - false_negatives_6: 8640.0000 - false_positives_6: 5255.0000\n",
      "Epoch 12: val_loss improved from 0.69122 to 0.69107, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 322ms/step - loss: 0.6912 - binary_accuracy: 0.5368 - false_negatives_6: 8640.0000 - false_positives_6: 5255.0000 - val_loss: 0.6911 - val_binary_accuracy: 0.5343 - val_false_negatives_6: 2937.0000 - val_false_positives_6: 1720.0000\n",
      "Epoch 13/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6909 - binary_accuracy: 0.5450 - false_negatives_6: 8595.0000 - false_positives_6: 5054.0000\n",
      "Epoch 13: val_loss improved from 0.69107 to 0.69091, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 324ms/step - loss: 0.6909 - binary_accuracy: 0.5450 - false_negatives_6: 8595.0000 - false_positives_6: 5054.0000 - val_loss: 0.6909 - val_binary_accuracy: 0.5336 - val_false_negatives_6: 2934.0000 - val_false_positives_6: 1730.0000\n",
      "Epoch 14/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6909 - binary_accuracy: 0.5408 - false_negatives_6: 8710.0000 - false_positives_6: 5067.0000\n",
      "Epoch 14: val_loss improved from 0.69091 to 0.69077, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 332ms/step - loss: 0.6909 - binary_accuracy: 0.5408 - false_negatives_6: 8710.0000 - false_positives_6: 5067.0000 - val_loss: 0.6908 - val_binary_accuracy: 0.5332 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1735.0000\n",
      "Epoch 15/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6907 - binary_accuracy: 0.5418 - false_negatives_6: 8787.0000 - false_positives_6: 4959.0000\n",
      "Epoch 15: val_loss improved from 0.69077 to 0.69062, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.6907 - binary_accuracy: 0.5418 - false_negatives_6: 8787.0000 - false_positives_6: 4959.0000 - val_loss: 0.6906 - val_binary_accuracy: 0.5337 - val_false_negatives_6: 2934.0000 - val_false_positives_6: 1729.0000\n",
      "Epoch 16/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6905 - binary_accuracy: 0.5439 - false_negatives_6: 8965.0000 - false_positives_6: 4717.0000\n",
      "Epoch 16: val_loss improved from 0.69062 to 0.69047, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 324ms/step - loss: 0.6905 - binary_accuracy: 0.5439 - false_negatives_6: 8965.0000 - false_positives_6: 4717.0000 - val_loss: 0.6905 - val_binary_accuracy: 0.5335 - val_false_negatives_6: 2934.0000 - val_false_positives_6: 1731.0000\n",
      "Epoch 17/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6902 - binary_accuracy: 0.5512 - false_negatives_6: 8906.0000 - false_positives_6: 4557.0000\n",
      "Epoch 17: val_loss improved from 0.69047 to 0.69032, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 320ms/step - loss: 0.6902 - binary_accuracy: 0.5512 - false_negatives_6: 8906.0000 - false_positives_6: 4557.0000 - val_loss: 0.6903 - val_binary_accuracy: 0.5337 - val_false_negatives_6: 2934.0000 - val_false_positives_6: 1729.0000\n",
      "Epoch 18/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6902 - binary_accuracy: 0.5472 - false_negatives_6: 9121.0000 - false_positives_6: 4462.0000\n",
      "Epoch 18: val_loss improved from 0.69032 to 0.69018, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.6902 - binary_accuracy: 0.5472 - false_negatives_6: 9121.0000 - false_positives_6: 4462.0000 - val_loss: 0.6902 - val_binary_accuracy: 0.5332 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1735.0000\n",
      "Epoch 19/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6901 - binary_accuracy: 0.5454 - false_negatives_6: 9131.0000 - false_positives_6: 4507.0000\n",
      "Epoch 19: val_loss improved from 0.69018 to 0.69004, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 37s 316ms/step - loss: 0.6901 - binary_accuracy: 0.5454 - false_negatives_6: 9131.0000 - false_positives_6: 4507.0000 - val_loss: 0.6900 - val_binary_accuracy: 0.5336 - val_false_negatives_6: 2934.0000 - val_false_positives_6: 1730.0000\n",
      "Epoch 20/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6896 - binary_accuracy: 0.5538 - false_negatives_6: 9237.0000 - false_positives_6: 4150.0000\n",
      "Epoch 20: val_loss improved from 0.69004 to 0.68990, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.6896 - binary_accuracy: 0.5538 - false_negatives_6: 9237.0000 - false_positives_6: 4150.0000 - val_loss: 0.6899 - val_binary_accuracy: 0.5331 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1736.0000\n",
      "Epoch 21/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6896 - binary_accuracy: 0.5478 - false_negatives_6: 9219.0000 - false_positives_6: 4346.0000\n",
      "Epoch 21: val_loss improved from 0.68990 to 0.68976, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 40s 335ms/step - loss: 0.6896 - binary_accuracy: 0.5478 - false_negatives_6: 9219.0000 - false_positives_6: 4346.0000 - val_loss: 0.6898 - val_binary_accuracy: 0.5328 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1739.0000\n",
      "Epoch 22/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6893 - binary_accuracy: 0.5542 - false_negatives_6: 9173.0000 - false_positives_6: 4201.0000\n",
      "Epoch 22: val_loss improved from 0.68976 to 0.68962, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 321ms/step - loss: 0.6893 - binary_accuracy: 0.5542 - false_negatives_6: 9173.0000 - false_positives_6: 4201.0000 - val_loss: 0.6896 - val_binary_accuracy: 0.5328 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1739.0000\n",
      "Epoch 23/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6895 - binary_accuracy: 0.5510 - false_negatives_6: 9317.0000 - false_positives_6: 4153.0000\n",
      "Epoch 23: val_loss improved from 0.68962 to 0.68949, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 40s 336ms/step - loss: 0.6895 - binary_accuracy: 0.5510 - false_negatives_6: 9317.0000 - false_positives_6: 4153.0000 - val_loss: 0.6895 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2933.0000 - val_false_positives_6: 1740.0000\n",
      "Epoch 24/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6892 - binary_accuracy: 0.5522 - false_negatives_6: 9279.0000 - false_positives_6: 4156.0000\n",
      "Epoch 24: val_loss improved from 0.68949 to 0.68936, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 330ms/step - loss: 0.6892 - binary_accuracy: 0.5522 - false_negatives_6: 9279.0000 - false_positives_6: 4156.0000 - val_loss: 0.6894 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2931.0000 - val_false_positives_6: 1742.0000\n",
      "Epoch 25/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6890 - binary_accuracy: 0.5546 - false_negatives_6: 9150.0000 - false_positives_6: 4213.0000\n",
      "Epoch 25: val_loss improved from 0.68936 to 0.68923, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 335ms/step - loss: 0.6890 - binary_accuracy: 0.5546 - false_negatives_6: 9150.0000 - false_positives_6: 4213.0000 - val_loss: 0.6892 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2931.0000 - val_false_positives_6: 1742.0000\n",
      "Epoch 26/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6890 - binary_accuracy: 0.5535 - false_negatives_6: 9222.0000 - false_positives_6: 4173.0000\n",
      "Epoch 26: val_loss improved from 0.68923 to 0.68911, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 327ms/step - loss: 0.6890 - binary_accuracy: 0.5535 - false_negatives_6: 9222.0000 - false_positives_6: 4173.0000 - val_loss: 0.6891 - val_binary_accuracy: 0.5326 - val_false_negatives_6: 2930.0000 - val_false_positives_6: 1744.0000\n",
      "Epoch 27/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6887 - binary_accuracy: 0.5539 - false_negatives_6: 9232.0000 - false_positives_6: 4150.0000\n",
      "Epoch 27: val_loss improved from 0.68911 to 0.68897, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.6887 - binary_accuracy: 0.5539 - false_negatives_6: 9232.0000 - false_positives_6: 4150.0000 - val_loss: 0.6890 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2930.0000 - val_false_positives_6: 1743.0000\n",
      "Epoch 28/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6883 - binary_accuracy: 0.5557 - false_negatives_6: 9122.0000 - false_positives_6: 4207.0000\n",
      "Epoch 28: val_loss improved from 0.68897 to 0.68883, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.6883 - binary_accuracy: 0.5557 - false_negatives_6: 9122.0000 - false_positives_6: 4207.0000 - val_loss: 0.6888 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2930.0000 - val_false_positives_6: 1743.0000\n",
      "Epoch 29/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6886 - binary_accuracy: 0.5534 - false_negatives_6: 9213.0000 - false_positives_6: 4184.0000\n",
      "Epoch 29: val_loss improved from 0.68883 to 0.68870, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 326ms/step - loss: 0.6886 - binary_accuracy: 0.5534 - false_negatives_6: 9213.0000 - false_positives_6: 4184.0000 - val_loss: 0.6887 - val_binary_accuracy: 0.5328 - val_false_negatives_6: 2929.0000 - val_false_positives_6: 1743.0000\n",
      "Epoch 30/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6882 - binary_accuracy: 0.5573 - false_negatives_6: 9164.0000 - false_positives_6: 4117.0000\n",
      "Epoch 30: val_loss improved from 0.68870 to 0.68856, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 326ms/step - loss: 0.6882 - binary_accuracy: 0.5573 - false_negatives_6: 9164.0000 - false_positives_6: 4117.0000 - val_loss: 0.6886 - val_binary_accuracy: 0.5328 - val_false_negatives_6: 2929.0000 - val_false_positives_6: 1743.0000\n",
      "Epoch 31/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6883 - binary_accuracy: 0.5520 - false_negatives_6: 9276.0000 - false_positives_6: 4163.0000\n",
      "Epoch 31: val_loss improved from 0.68856 to 0.68843, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 327ms/step - loss: 0.6883 - binary_accuracy: 0.5520 - false_negatives_6: 9276.0000 - false_positives_6: 4163.0000 - val_loss: 0.6884 - val_binary_accuracy: 0.5328 - val_false_negatives_6: 2929.0000 - val_false_positives_6: 1743.0000\n",
      "Epoch 32/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6880 - binary_accuracy: 0.5543 - false_negatives_6: 9256.0000 - false_positives_6: 4116.0000\n",
      "Epoch 32: val_loss improved from 0.68843 to 0.68830, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 324ms/step - loss: 0.6880 - binary_accuracy: 0.5543 - false_negatives_6: 9256.0000 - false_positives_6: 4116.0000 - val_loss: 0.6883 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2929.0000 - val_false_positives_6: 1744.0000\n",
      "Epoch 33/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6877 - binary_accuracy: 0.5583 - false_negatives_6: 9221.0000 - false_positives_6: 4030.0000\n",
      "Epoch 33: val_loss improved from 0.68830 to 0.68816, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.6877 - binary_accuracy: 0.5583 - false_negatives_6: 9221.0000 - false_positives_6: 4030.0000 - val_loss: 0.6882 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2929.0000 - val_false_positives_6: 1744.0000\n",
      "Epoch 34/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6877 - binary_accuracy: 0.5564 - false_negatives_6: 9179.0000 - false_positives_6: 4128.0000\n",
      "Epoch 34: val_loss improved from 0.68816 to 0.68803, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 331ms/step - loss: 0.6877 - binary_accuracy: 0.5564 - false_negatives_6: 9179.0000 - false_positives_6: 4128.0000 - val_loss: 0.6880 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 35/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6878 - binary_accuracy: 0.5527 - false_negatives_6: 9210.0000 - false_positives_6: 4208.0000\n",
      "Epoch 35: val_loss improved from 0.68803 to 0.68791, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 37s 316ms/step - loss: 0.6878 - binary_accuracy: 0.5527 - false_negatives_6: 9210.0000 - false_positives_6: 4208.0000 - val_loss: 0.6879 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 36/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6877 - binary_accuracy: 0.5527 - false_negatives_6: 9174.0000 - false_positives_6: 4245.0000\n",
      "Epoch 36: val_loss improved from 0.68791 to 0.68778, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 322ms/step - loss: 0.6877 - binary_accuracy: 0.5527 - false_negatives_6: 9174.0000 - false_positives_6: 4245.0000 - val_loss: 0.6878 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 37/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6874 - binary_accuracy: 0.5572 - false_negatives_6: 9144.0000 - false_positives_6: 4139.0000\n",
      "Epoch 37: val_loss improved from 0.68778 to 0.68765, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 328ms/step - loss: 0.6874 - binary_accuracy: 0.5572 - false_negatives_6: 9144.0000 - false_positives_6: 4139.0000 - val_loss: 0.6876 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 38/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6870 - binary_accuracy: 0.5552 - false_negatives_6: 9200.0000 - false_positives_6: 4145.0000\n",
      "Epoch 38: val_loss improved from 0.68765 to 0.68751, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 39s 329ms/step - loss: 0.6870 - binary_accuracy: 0.5552 - false_negatives_6: 9200.0000 - false_positives_6: 4145.0000 - val_loss: 0.6875 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 39/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6869 - binary_accuracy: 0.5577 - false_negatives_6: 9121.0000 - false_positives_6: 4148.0000\n",
      "Epoch 39: val_loss improved from 0.68751 to 0.68738, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 318ms/step - loss: 0.6869 - binary_accuracy: 0.5577 - false_negatives_6: 9121.0000 - false_positives_6: 4148.0000 - val_loss: 0.6874 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "Epoch 40/40\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.6865 - binary_accuracy: 0.5547 - false_negatives_6: 9140.0000 - false_positives_6: 4220.0000\n",
      "Epoch 40: val_loss improved from 0.68738 to 0.68723, saving model to model/active/Adagrad_Model.h5\n",
      "118/118 [==============================] - 38s 318ms/step - loss: 0.6865 - binary_accuracy: 0.5547 - false_negatives_6: 9140.0000 - false_positives_6: 4220.0000 - val_loss: 0.6872 - val_binary_accuracy: 0.5327 - val_false_negatives_6: 2928.0000 - val_false_positives_6: 1745.0000\n",
      "40/40 [==============================] - 4s 89ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 2867.0, Number of ones incorrectly classified: 1373.0\n",
      "Sample ratio for positives: 0.32382075471698113, Sample ratio for negatives:0.6761792452830189\n",
      "Starting training with 39999 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6834 - binary_accuracy: 0.5866 - false_negatives_7: 11113.0000 - false_positives_7: 5422.0000\n",
      "Epoch 1: val_loss improved from 0.68723 to 0.68709, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 55s 319ms/step - loss: 0.6834 - binary_accuracy: 0.5866 - false_negatives_7: 11113.0000 - false_positives_7: 5422.0000 - val_loss: 0.6871 - val_binary_accuracy: 0.5407 - val_false_negatives_7: 2973.0000 - val_false_positives_7: 1620.0000\n",
      "Epoch 2/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6821 - binary_accuracy: 0.5864 - false_negatives_7: 12782.0000 - false_positives_7: 3762.0000\n",
      "Epoch 2: val_loss improved from 0.68709 to 0.68697, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 316ms/step - loss: 0.6821 - binary_accuracy: 0.5864 - false_negatives_7: 12782.0000 - false_positives_7: 3762.0000 - val_loss: 0.6870 - val_binary_accuracy: 0.5568 - val_false_negatives_7: 3051.0000 - val_false_positives_7: 1381.0000\n",
      "Epoch 3/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6816 - binary_accuracy: 0.5837 - false_negatives_7: 13494.0000 - false_positives_7: 3156.0000\n",
      "Epoch 3: val_loss improved from 0.68697 to 0.68686, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 52s 330ms/step - loss: 0.6816 - binary_accuracy: 0.5837 - false_negatives_7: 13494.0000 - false_positives_7: 3156.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.5681 - val_false_negatives_7: 3086.0000 - val_false_positives_7: 1233.0000\n",
      "Epoch 4/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6811 - binary_accuracy: 0.5876 - false_negatives_7: 13639.0000 - false_positives_7: 2856.0000\n",
      "Epoch 4: val_loss improved from 0.68686 to 0.68671, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 326ms/step - loss: 0.6811 - binary_accuracy: 0.5876 - false_negatives_7: 13639.0000 - false_positives_7: 2856.0000 - val_loss: 0.6867 - val_binary_accuracy: 0.5714 - val_false_negatives_7: 3099.0000 - val_false_positives_7: 1187.0000\n",
      "Epoch 5/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6806 - binary_accuracy: 0.5892 - false_negatives_7: 13755.0000 - false_positives_7: 2676.0000\n",
      "Epoch 5: val_loss improved from 0.68671 to 0.68649, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 324ms/step - loss: 0.6806 - binary_accuracy: 0.5892 - false_negatives_7: 13755.0000 - false_positives_7: 2676.0000 - val_loss: 0.6865 - val_binary_accuracy: 0.5648 - val_false_negatives_7: 3083.0000 - val_false_positives_7: 1269.0000\n",
      "Epoch 6/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6797 - binary_accuracy: 0.5865 - false_negatives_7: 13819.0000 - false_positives_7: 2719.0000\n",
      "Epoch 6: val_loss improved from 0.68649 to 0.68628, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 313ms/step - loss: 0.6797 - binary_accuracy: 0.5865 - false_negatives_7: 13819.0000 - false_positives_7: 2719.0000 - val_loss: 0.6863 - val_binary_accuracy: 0.5596 - val_false_negatives_7: 3063.0000 - val_false_positives_7: 1341.0000\n",
      "Epoch 7/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6796 - binary_accuracy: 0.5870 - false_negatives_7: 13809.0000 - false_positives_7: 2709.0000\n",
      "Epoch 7: val_loss improved from 0.68628 to 0.68604, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 311ms/step - loss: 0.6796 - binary_accuracy: 0.5870 - false_negatives_7: 13809.0000 - false_positives_7: 2709.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.5530 - val_false_negatives_7: 3032.0000 - val_false_positives_7: 1438.0000\n",
      "Epoch 8/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6792 - binary_accuracy: 0.5865 - false_negatives_7: 13724.0000 - false_positives_7: 2816.0000\n",
      "Epoch 8: val_loss improved from 0.68604 to 0.68579, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 316ms/step - loss: 0.6792 - binary_accuracy: 0.5865 - false_negatives_7: 13724.0000 - false_positives_7: 2816.0000 - val_loss: 0.6858 - val_binary_accuracy: 0.5477 - val_false_negatives_7: 3012.0000 - val_false_positives_7: 1511.0000\n",
      "Epoch 9/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6786 - binary_accuracy: 0.5873 - false_negatives_7: 13630.0000 - false_positives_7: 2879.0000\n",
      "Epoch 9: val_loss improved from 0.68579 to 0.68556, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 313ms/step - loss: 0.6786 - binary_accuracy: 0.5873 - false_negatives_7: 13630.0000 - false_positives_7: 2879.0000 - val_loss: 0.6856 - val_binary_accuracy: 0.5444 - val_false_negatives_7: 3000.0000 - val_false_positives_7: 1556.0000\n",
      "Epoch 10/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6783 - binary_accuracy: 0.5879 - false_negatives_7: 13638.0000 - false_positives_7: 2845.0000\n",
      "Epoch 10: val_loss improved from 0.68556 to 0.68539, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 326ms/step - loss: 0.6783 - binary_accuracy: 0.5879 - false_negatives_7: 13638.0000 - false_positives_7: 2845.0000 - val_loss: 0.6854 - val_binary_accuracy: 0.5441 - val_false_negatives_7: 3000.0000 - val_false_positives_7: 1559.0000\n",
      "Epoch 11/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6778 - binary_accuracy: 0.5870 - false_negatives_7: 13628.0000 - false_positives_7: 2891.0000\n",
      "Epoch 11: val_loss improved from 0.68539 to 0.68519, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 324ms/step - loss: 0.6778 - binary_accuracy: 0.5870 - false_negatives_7: 13628.0000 - false_positives_7: 2891.0000 - val_loss: 0.6852 - val_binary_accuracy: 0.5437 - val_false_negatives_7: 2991.0000 - val_false_positives_7: 1572.0000\n",
      "Epoch 12/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6778 - binary_accuracy: 0.5873 - false_negatives_7: 13540.0000 - false_positives_7: 2967.0000\n",
      "Epoch 12: val_loss improved from 0.68519 to 0.68496, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 64s 406ms/step - loss: 0.6778 - binary_accuracy: 0.5873 - false_negatives_7: 13540.0000 - false_positives_7: 2967.0000 - val_loss: 0.6850 - val_binary_accuracy: 0.5422 - val_false_negatives_7: 2983.0000 - val_false_positives_7: 1595.0000\n",
      "Epoch 13/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6775 - binary_accuracy: 0.5873 - false_negatives_7: 13544.0000 - false_positives_7: 2964.0000\n",
      "Epoch 13: val_loss improved from 0.68496 to 0.68475, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 66s 420ms/step - loss: 0.6775 - binary_accuracy: 0.5873 - false_negatives_7: 13544.0000 - false_positives_7: 2964.0000 - val_loss: 0.6848 - val_binary_accuracy: 0.5413 - val_false_negatives_7: 2976.0000 - val_false_positives_7: 1611.0000\n",
      "Epoch 14/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6770 - binary_accuracy: 0.5883 - false_negatives_7: 13568.0000 - false_positives_7: 2901.0000\n",
      "Epoch 14: val_loss improved from 0.68475 to 0.68452, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 64s 409ms/step - loss: 0.6770 - binary_accuracy: 0.5883 - false_negatives_7: 13568.0000 - false_positives_7: 2901.0000 - val_loss: 0.6845 - val_binary_accuracy: 0.5404 - val_false_negatives_7: 2969.0000 - val_false_positives_7: 1627.0000\n",
      "Epoch 15/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6767 - binary_accuracy: 0.5866 - false_negatives_7: 13553.0000 - false_positives_7: 2984.0000\n",
      "Epoch 15: val_loss improved from 0.68452 to 0.68431, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 52s 328ms/step - loss: 0.6767 - binary_accuracy: 0.5866 - false_negatives_7: 13553.0000 - false_positives_7: 2984.0000 - val_loss: 0.6843 - val_binary_accuracy: 0.5403 - val_false_negatives_7: 2968.0000 - val_false_positives_7: 1629.0000\n",
      "Epoch 16/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6761 - binary_accuracy: 0.5864 - false_negatives_7: 13528.0000 - false_positives_7: 3017.0000\n",
      "Epoch 16: val_loss improved from 0.68431 to 0.68411, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 326ms/step - loss: 0.6761 - binary_accuracy: 0.5864 - false_negatives_7: 13528.0000 - false_positives_7: 3017.0000 - val_loss: 0.6841 - val_binary_accuracy: 0.5399 - val_false_negatives_7: 2967.0000 - val_false_positives_7: 1634.0000\n",
      "Epoch 17/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6758 - binary_accuracy: 0.5875 - false_negatives_7: 13490.0000 - false_positives_7: 3011.0000\n",
      "Epoch 17: val_loss improved from 0.68411 to 0.68387, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 326ms/step - loss: 0.6758 - binary_accuracy: 0.5875 - false_negatives_7: 13490.0000 - false_positives_7: 3011.0000 - val_loss: 0.6839 - val_binary_accuracy: 0.5395 - val_false_negatives_7: 2964.0000 - val_false_positives_7: 1641.0000\n",
      "Epoch 18/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6758 - binary_accuracy: 0.5876 - false_negatives_7: 13472.0000 - false_positives_7: 3022.0000\n",
      "Epoch 18: val_loss improved from 0.68387 to 0.68364, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 322ms/step - loss: 0.6758 - binary_accuracy: 0.5876 - false_negatives_7: 13472.0000 - false_positives_7: 3022.0000 - val_loss: 0.6836 - val_binary_accuracy: 0.5387 - val_false_negatives_7: 2963.0000 - val_false_positives_7: 1650.0000\n",
      "Epoch 19/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6755 - binary_accuracy: 0.5881 - false_negatives_7: 13414.0000 - false_positives_7: 3061.0000\n",
      "Epoch 19: val_loss improved from 0.68364 to 0.68339, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 1236s 8s/step - loss: 0.6755 - binary_accuracy: 0.5881 - false_negatives_7: 13414.0000 - false_positives_7: 3061.0000 - val_loss: 0.6834 - val_binary_accuracy: 0.5382 - val_false_negatives_7: 2961.0000 - val_false_positives_7: 1657.0000\n",
      "Epoch 20/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6753 - binary_accuracy: 0.5866 - false_negatives_7: 13430.0000 - false_positives_7: 3105.0000\n",
      "Epoch 20: val_loss improved from 0.68339 to 0.68317, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 313ms/step - loss: 0.6753 - binary_accuracy: 0.5866 - false_negatives_7: 13430.0000 - false_positives_7: 3105.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.5381 - val_false_negatives_7: 2961.0000 - val_false_positives_7: 1658.0000\n",
      "Epoch 21/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6747 - binary_accuracy: 0.5887 - false_negatives_7: 13404.0000 - false_positives_7: 3048.0000\n",
      "Epoch 21: val_loss improved from 0.68317 to 0.68294, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 0.6747 - binary_accuracy: 0.5887 - false_negatives_7: 13404.0000 - false_positives_7: 3048.0000 - val_loss: 0.6829 - val_binary_accuracy: 0.5381 - val_false_negatives_7: 2962.0000 - val_false_positives_7: 1657.0000\n",
      "Epoch 22/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6750 - binary_accuracy: 0.5882 - false_negatives_7: 13323.0000 - false_positives_7: 3147.0000\n",
      "Epoch 22: val_loss improved from 0.68294 to 0.68268, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 53s 339ms/step - loss: 0.6750 - binary_accuracy: 0.5882 - false_negatives_7: 13323.0000 - false_positives_7: 3147.0000 - val_loss: 0.6827 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2961.0000 - val_false_positives_7: 1660.0000\n",
      "Epoch 23/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6750 - binary_accuracy: 0.5884 - false_negatives_7: 13326.0000 - false_positives_7: 3138.0000\n",
      "Epoch 23: val_loss improved from 0.68268 to 0.68243, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 62s 395ms/step - loss: 0.6750 - binary_accuracy: 0.5884 - false_negatives_7: 13326.0000 - false_positives_7: 3138.0000 - val_loss: 0.6824 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2960.0000 - val_false_positives_7: 1661.0000\n",
      "Epoch 24/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6740 - binary_accuracy: 0.5881 - false_negatives_7: 13308.0000 - false_positives_7: 3167.0000\n",
      "Epoch 24: val_loss improved from 0.68243 to 0.68216, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 45s 285ms/step - loss: 0.6740 - binary_accuracy: 0.5881 - false_negatives_7: 13308.0000 - false_positives_7: 3167.0000 - val_loss: 0.6822 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1662.0000\n",
      "Epoch 25/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6734 - binary_accuracy: 0.5903 - false_negatives_7: 13302.0000 - false_positives_7: 3084.0000\n",
      "Epoch 25: val_loss improved from 0.68216 to 0.68188, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.6734 - binary_accuracy: 0.5903 - false_negatives_7: 13302.0000 - false_positives_7: 3084.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1662.0000\n",
      "Epoch 26/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6729 - binary_accuracy: 0.5894 - false_negatives_7: 13357.0000 - false_positives_7: 3065.0000\n",
      "Epoch 26: val_loss improved from 0.68188 to 0.68164, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 53s 335ms/step - loss: 0.6729 - binary_accuracy: 0.5894 - false_negatives_7: 13357.0000 - false_positives_7: 3065.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.5378 - val_false_negatives_7: 2960.0000 - val_false_positives_7: 1662.0000\n",
      "Epoch 27/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6727 - binary_accuracy: 0.5908 - false_negatives_7: 13250.0000 - false_positives_7: 3118.0000\n",
      "Epoch 27: val_loss improved from 0.68164 to 0.68137, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 53s 338ms/step - loss: 0.6727 - binary_accuracy: 0.5908 - false_negatives_7: 13250.0000 - false_positives_7: 3118.0000 - val_loss: 0.6814 - val_binary_accuracy: 0.5378 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1663.0000\n",
      "Epoch 28/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6715 - binary_accuracy: 0.5903 - false_negatives_7: 13250.0000 - false_positives_7: 3136.0000\n",
      "Epoch 28: val_loss improved from 0.68137 to 0.68110, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 53s 335ms/step - loss: 0.6715 - binary_accuracy: 0.5903 - false_negatives_7: 13250.0000 - false_positives_7: 3136.0000 - val_loss: 0.6811 - val_binary_accuracy: 0.5377 - val_false_negatives_7: 2957.0000 - val_false_positives_7: 1666.0000\n",
      "Epoch 29/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6728 - binary_accuracy: 0.5903 - false_negatives_7: 13257.0000 - false_positives_7: 3132.0000\n",
      "Epoch 29: val_loss improved from 0.68110 to 0.68080, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 52s 328ms/step - loss: 0.6728 - binary_accuracy: 0.5903 - false_negatives_7: 13257.0000 - false_positives_7: 3132.0000 - val_loss: 0.6808 - val_binary_accuracy: 0.5375 - val_false_negatives_7: 2957.0000 - val_false_positives_7: 1668.0000\n",
      "Epoch 30/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6714 - binary_accuracy: 0.5924 - false_negatives_7: 13170.0000 - false_positives_7: 3135.0000\n",
      "Epoch 30: val_loss improved from 0.68080 to 0.68051, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 326ms/step - loss: 0.6714 - binary_accuracy: 0.5924 - false_negatives_7: 13170.0000 - false_positives_7: 3135.0000 - val_loss: 0.6805 - val_binary_accuracy: 0.5376 - val_false_negatives_7: 2956.0000 - val_false_positives_7: 1668.0000\n",
      "Epoch 31/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6710 - binary_accuracy: 0.5928 - false_negatives_7: 13207.0000 - false_positives_7: 3081.0000\n",
      "Epoch 31: val_loss improved from 0.68051 to 0.68020, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 317ms/step - loss: 0.6710 - binary_accuracy: 0.5928 - false_negatives_7: 13207.0000 - false_positives_7: 3081.0000 - val_loss: 0.6802 - val_binary_accuracy: 0.5375 - val_false_negatives_7: 2957.0000 - val_false_positives_7: 1668.0000\n",
      "Epoch 32/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6707 - binary_accuracy: 0.5913 - false_negatives_7: 13179.0000 - false_positives_7: 3168.0000\n",
      "Epoch 32: val_loss improved from 0.68020 to 0.67992, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 317ms/step - loss: 0.6707 - binary_accuracy: 0.5913 - false_negatives_7: 13179.0000 - false_positives_7: 3168.0000 - val_loss: 0.6799 - val_binary_accuracy: 0.5376 - val_false_negatives_7: 2958.0000 - val_false_positives_7: 1666.0000\n",
      "Epoch 33/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6705 - binary_accuracy: 0.5920 - false_negatives_7: 13172.0000 - false_positives_7: 3146.0000\n",
      "Epoch 33: val_loss improved from 0.67992 to 0.67963, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 322ms/step - loss: 0.6705 - binary_accuracy: 0.5920 - false_negatives_7: 13172.0000 - false_positives_7: 3146.0000 - val_loss: 0.6796 - val_binary_accuracy: 0.5378 - val_false_negatives_7: 2958.0000 - val_false_positives_7: 1664.0000\n",
      "Epoch 34/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6699 - binary_accuracy: 0.5935 - false_negatives_7: 13175.0000 - false_positives_7: 3083.0000\n",
      "Epoch 34: val_loss improved from 0.67963 to 0.67929, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 319ms/step - loss: 0.6699 - binary_accuracy: 0.5935 - false_negatives_7: 13175.0000 - false_positives_7: 3083.0000 - val_loss: 0.6793 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2960.0000 - val_false_positives_7: 1661.0000\n",
      "Epoch 35/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6700 - binary_accuracy: 0.5926 - false_negatives_7: 13198.0000 - false_positives_7: 3097.0000\n",
      "Epoch 35: val_loss improved from 0.67929 to 0.67896, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.6700 - binary_accuracy: 0.5926 - false_negatives_7: 13198.0000 - false_positives_7: 3097.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.5379 - val_false_negatives_7: 2960.0000 - val_false_positives_7: 1661.0000\n",
      "Epoch 36/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6693 - binary_accuracy: 0.5929 - false_negatives_7: 13134.0000 - false_positives_7: 3149.0000\n",
      "Epoch 36: val_loss improved from 0.67896 to 0.67864, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 327ms/step - loss: 0.6693 - binary_accuracy: 0.5929 - false_negatives_7: 13134.0000 - false_positives_7: 3149.0000 - val_loss: 0.6786 - val_binary_accuracy: 0.5380 - val_false_negatives_7: 2960.0000 - val_false_positives_7: 1660.0000\n",
      "Epoch 37/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6690 - binary_accuracy: 0.5940 - false_negatives_7: 13167.0000 - false_positives_7: 3072.0000\n",
      "Epoch 37: val_loss improved from 0.67864 to 0.67829, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 311ms/step - loss: 0.6690 - binary_accuracy: 0.5940 - false_negatives_7: 13167.0000 - false_positives_7: 3072.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.5380 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1661.0000\n",
      "Epoch 38/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6686 - binary_accuracy: 0.5935 - false_negatives_7: 13157.0000 - false_positives_7: 3103.0000\n",
      "Epoch 38: val_loss improved from 0.67829 to 0.67794, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 51s 323ms/step - loss: 0.6686 - binary_accuracy: 0.5935 - false_negatives_7: 13157.0000 - false_positives_7: 3103.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.5381 - val_false_negatives_7: 2958.0000 - val_false_positives_7: 1661.0000\n",
      "Epoch 39/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6681 - binary_accuracy: 0.5932 - false_negatives_7: 13128.0000 - false_positives_7: 3142.0000\n",
      "Epoch 39: val_loss improved from 0.67794 to 0.67758, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 312ms/step - loss: 0.6681 - binary_accuracy: 0.5932 - false_negatives_7: 13128.0000 - false_positives_7: 3142.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.5384 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1657.0000\n",
      "Epoch 40/40\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6687 - binary_accuracy: 0.5963 - false_negatives_7: 13089.0000 - false_positives_7: 3060.0000\n",
      "Epoch 40: val_loss improved from 0.67758 to 0.67721, saving model to model/active/Adagrad_Model.h5\n",
      "157/157 [==============================] - 49s 312ms/step - loss: 0.6687 - binary_accuracy: 0.5963 - false_negatives_7: 13089.0000 - false_positives_7: 3060.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.5389 - val_false_negatives_7: 2959.0000 - val_false_positives_7: 1652.0000\n",
      "40/40 [==============================] - 6s 129ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 2908.0, Number of ones incorrectly classified: 1266.0\n",
      "Sample ratio for positives: 0.30330618112122665, Sample ratio for negatives:0.6966938188787734\n",
      "Starting training with 47655 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6668 - binary_accuracy: 0.5970 - false_negatives_8: 15122.0000 - false_positives_8: 4085.0000\n",
      "Epoch 1: val_loss improved from 0.67721 to 0.67679, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 69s 342ms/step - loss: 0.6668 - binary_accuracy: 0.5970 - false_negatives_8: 15122.0000 - false_positives_8: 4085.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.5439 - val_false_negatives_8: 2993.0000 - val_false_positives_8: 1568.0000\n",
      "Epoch 2/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6659 - binary_accuracy: 0.5993 - false_negatives_8: 15344.0000 - false_positives_8: 3749.0000\n",
      "Epoch 2: val_loss improved from 0.67679 to 0.67630, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 64s 341ms/step - loss: 0.6659 - binary_accuracy: 0.5993 - false_negatives_8: 15344.0000 - false_positives_8: 3749.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.5477 - val_false_negatives_8: 3000.0000 - val_false_positives_8: 1523.0000\n",
      "Epoch 3/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6655 - binary_accuracy: 0.5998 - false_negatives_8: 15413.0000 - false_positives_8: 3658.0000\n",
      "Epoch 3: val_loss improved from 0.67630 to 0.67574, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 61s 327ms/step - loss: 0.6655 - binary_accuracy: 0.5998 - false_negatives_8: 15413.0000 - false_positives_8: 3658.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.5487 - val_false_negatives_8: 3006.0000 - val_false_positives_8: 1507.0000\n",
      "Epoch 4/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6647 - binary_accuracy: 0.6019 - false_negatives_8: 15435.0000 - false_positives_8: 3538.0000\n",
      "Epoch 4: val_loss improved from 0.67574 to 0.67523, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 61s 328ms/step - loss: 0.6647 - binary_accuracy: 0.6019 - false_negatives_8: 15435.0000 - false_positives_8: 3538.0000 - val_loss: 0.6752 - val_binary_accuracy: 0.5533 - val_false_negatives_8: 3011.0000 - val_false_positives_8: 1456.0000\n",
      "Epoch 5/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6648 - binary_accuracy: 0.6007 - false_negatives_8: 15456.0000 - false_positives_8: 3571.0000\n",
      "Epoch 5: val_loss improved from 0.67523 to 0.67467, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 63s 338ms/step - loss: 0.6648 - binary_accuracy: 0.6007 - false_negatives_8: 15456.0000 - false_positives_8: 3571.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.5545 - val_false_negatives_8: 3016.0000 - val_false_positives_8: 1439.0000\n",
      "Epoch 6/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6645 - binary_accuracy: 0.6026 - false_negatives_8: 15391.0000 - false_positives_8: 3549.0000\n",
      "Epoch 6: val_loss improved from 0.67467 to 0.67408, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 63s 336ms/step - loss: 0.6645 - binary_accuracy: 0.6026 - false_negatives_8: 15391.0000 - false_positives_8: 3549.0000 - val_loss: 0.6741 - val_binary_accuracy: 0.5541 - val_false_negatives_8: 3015.0000 - val_false_positives_8: 1444.0000\n",
      "Epoch 7/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6632 - binary_accuracy: 0.6022 - false_negatives_8: 15418.0000 - false_positives_8: 3541.0000\n",
      "Epoch 7: val_loss improved from 0.67408 to 0.67352, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 318ms/step - loss: 0.6632 - binary_accuracy: 0.6022 - false_negatives_8: 15418.0000 - false_positives_8: 3541.0000 - val_loss: 0.6735 - val_binary_accuracy: 0.5568 - val_false_negatives_8: 3022.0000 - val_false_positives_8: 1410.0000\n",
      "Epoch 8/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6625 - binary_accuracy: 0.6035 - false_negatives_8: 15388.0000 - false_positives_8: 3505.0000\n",
      "Epoch 8: val_loss improved from 0.67352 to 0.67293, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 316ms/step - loss: 0.6625 - binary_accuracy: 0.6035 - false_negatives_8: 15388.0000 - false_positives_8: 3505.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.5580 - val_false_negatives_8: 3027.0000 - val_false_positives_8: 1393.0000\n",
      "Epoch 9/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6624 - binary_accuracy: 0.6052 - false_negatives_8: 15297.0000 - false_positives_8: 3518.0000\n",
      "Epoch 9: val_loss improved from 0.67293 to 0.67229, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 319ms/step - loss: 0.6624 - binary_accuracy: 0.6052 - false_negatives_8: 15297.0000 - false_positives_8: 3518.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.5583 - val_false_negatives_8: 3027.0000 - val_false_positives_8: 1390.0000\n",
      "Epoch 10/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6613 - binary_accuracy: 0.6043 - false_negatives_8: 15330.0000 - false_positives_8: 3527.0000\n",
      "Epoch 10: val_loss improved from 0.67229 to 0.67167, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 315ms/step - loss: 0.6613 - binary_accuracy: 0.6043 - false_negatives_8: 15330.0000 - false_positives_8: 3527.0000 - val_loss: 0.6717 - val_binary_accuracy: 0.5619 - val_false_negatives_8: 3035.0000 - val_false_positives_8: 1346.0000\n",
      "Epoch 11/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6608 - binary_accuracy: 0.6085 - false_negatives_8: 15235.0000 - false_positives_8: 3421.0000\n",
      "Epoch 11: val_loss improved from 0.67167 to 0.67103, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6608 - binary_accuracy: 0.6085 - false_negatives_8: 15235.0000 - false_positives_8: 3421.0000 - val_loss: 0.6710 - val_binary_accuracy: 0.5630 - val_false_negatives_8: 3038.0000 - val_false_positives_8: 1332.0000\n",
      "Epoch 12/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6609 - binary_accuracy: 0.6064 - false_negatives_8: 15212.0000 - false_positives_8: 3545.0000\n",
      "Epoch 12: val_loss improved from 0.67103 to 0.67036, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 318ms/step - loss: 0.6609 - binary_accuracy: 0.6064 - false_negatives_8: 15212.0000 - false_positives_8: 3545.0000 - val_loss: 0.6704 - val_binary_accuracy: 0.5639 - val_false_negatives_8: 3040.0000 - val_false_positives_8: 1321.0000\n",
      "Epoch 13/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6600 - binary_accuracy: 0.6077 - false_negatives_8: 15188.0000 - false_positives_8: 3505.0000\n",
      "Epoch 13: val_loss improved from 0.67036 to 0.66970, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 61s 324ms/step - loss: 0.6600 - binary_accuracy: 0.6077 - false_negatives_8: 15188.0000 - false_positives_8: 3505.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.5665 - val_false_negatives_8: 3044.0000 - val_false_positives_8: 1291.0000\n",
      "Epoch 14/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6592 - binary_accuracy: 0.6078 - false_negatives_8: 15165.0000 - false_positives_8: 3525.0000\n",
      "Epoch 14: val_loss improved from 0.66970 to 0.66904, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 62s 331ms/step - loss: 0.6592 - binary_accuracy: 0.6078 - false_negatives_8: 15165.0000 - false_positives_8: 3525.0000 - val_loss: 0.6690 - val_binary_accuracy: 0.5674 - val_false_negatives_8: 3052.0000 - val_false_positives_8: 1274.0000\n",
      "Epoch 15/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6588 - binary_accuracy: 0.6120 - false_negatives_8: 14984.0000 - false_positives_8: 3505.0000\n",
      "Epoch 15: val_loss improved from 0.66904 to 0.66831, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 63s 337ms/step - loss: 0.6588 - binary_accuracy: 0.6120 - false_negatives_8: 14984.0000 - false_positives_8: 3505.0000 - val_loss: 0.6683 - val_binary_accuracy: 0.5676 - val_false_negatives_8: 3052.0000 - val_false_positives_8: 1272.0000\n",
      "Epoch 16/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6581 - binary_accuracy: 0.6138 - false_negatives_8: 14921.0000 - false_positives_8: 3485.0000\n",
      "Epoch 16: val_loss improved from 0.66831 to 0.66763, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6581 - binary_accuracy: 0.6138 - false_negatives_8: 14921.0000 - false_positives_8: 3485.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.5702 - val_false_negatives_8: 3063.0000 - val_false_positives_8: 1235.0000\n",
      "Epoch 17/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6573 - binary_accuracy: 0.6131 - false_negatives_8: 14983.0000 - false_positives_8: 3455.0000\n",
      "Epoch 17: val_loss improved from 0.66763 to 0.66690, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.6573 - binary_accuracy: 0.6131 - false_negatives_8: 14983.0000 - false_positives_8: 3455.0000 - val_loss: 0.6669 - val_binary_accuracy: 0.5714 - val_false_negatives_8: 3070.0000 - val_false_positives_8: 1216.0000\n",
      "Epoch 18/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6567 - binary_accuracy: 0.6157 - false_negatives_8: 14824.0000 - false_positives_8: 3489.0000\n",
      "Epoch 18: val_loss improved from 0.66690 to 0.66614, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 320ms/step - loss: 0.6567 - binary_accuracy: 0.6157 - false_negatives_8: 14824.0000 - false_positives_8: 3489.0000 - val_loss: 0.6661 - val_binary_accuracy: 0.5731 - val_false_negatives_8: 3076.0000 - val_false_positives_8: 1193.0000\n",
      "Epoch 19/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6558 - binary_accuracy: 0.6187 - false_negatives_8: 14661.0000 - false_positives_8: 3510.0000\n",
      "Epoch 19: val_loss improved from 0.66614 to 0.66539, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 316ms/step - loss: 0.6558 - binary_accuracy: 0.6187 - false_negatives_8: 14661.0000 - false_positives_8: 3510.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.5758 - val_false_negatives_8: 3080.0000 - val_false_positives_8: 1162.0000\n",
      "Epoch 20/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.6180 - false_negatives_8: 14698.0000 - false_positives_8: 3505.0000\n",
      "Epoch 20: val_loss improved from 0.66539 to 0.66461, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6543 - binary_accuracy: 0.6180 - false_negatives_8: 14698.0000 - false_positives_8: 3505.0000 - val_loss: 0.6646 - val_binary_accuracy: 0.5778 - val_false_negatives_8: 3088.0000 - val_false_positives_8: 1134.0000\n",
      "Epoch 21/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.6213 - false_negatives_8: 14563.0000 - false_positives_8: 3485.0000\n",
      "Epoch 21: val_loss improved from 0.66461 to 0.66385, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 317ms/step - loss: 0.6543 - binary_accuracy: 0.6213 - false_negatives_8: 14563.0000 - false_positives_8: 3485.0000 - val_loss: 0.6638 - val_binary_accuracy: 0.5784 - val_false_negatives_8: 3088.0000 - val_false_positives_8: 1128.0000\n",
      "Epoch 22/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6533 - binary_accuracy: 0.6215 - false_negatives_8: 14501.0000 - false_positives_8: 3536.0000\n",
      "Epoch 22: val_loss improved from 0.66385 to 0.66304, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6533 - binary_accuracy: 0.6215 - false_negatives_8: 14501.0000 - false_positives_8: 3536.0000 - val_loss: 0.6630 - val_binary_accuracy: 0.5820 - val_false_negatives_8: 3095.0000 - val_false_positives_8: 1085.0000\n",
      "Epoch 23/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6531 - binary_accuracy: 0.6219 - false_negatives_8: 14426.0000 - false_positives_8: 3590.0000\n",
      "Epoch 23: val_loss improved from 0.66304 to 0.66223, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 319ms/step - loss: 0.6531 - binary_accuracy: 0.6219 - false_negatives_8: 14426.0000 - false_positives_8: 3590.0000 - val_loss: 0.6622 - val_binary_accuracy: 0.5843 - val_false_negatives_8: 3099.0000 - val_false_positives_8: 1058.0000\n",
      "Epoch 24/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6526 - binary_accuracy: 0.6262 - false_negatives_8: 14227.0000 - false_positives_8: 3586.0000\n",
      "Epoch 24: val_loss improved from 0.66223 to 0.66140, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 323ms/step - loss: 0.6526 - binary_accuracy: 0.6262 - false_negatives_8: 14227.0000 - false_positives_8: 3586.0000 - val_loss: 0.6614 - val_binary_accuracy: 0.5865 - val_false_negatives_8: 3087.0000 - val_false_positives_8: 1048.0000\n",
      "Epoch 25/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6517 - binary_accuracy: 0.6253 - false_negatives_8: 14252.0000 - false_positives_8: 3602.0000\n",
      "Epoch 25: val_loss improved from 0.66140 to 0.66052, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 317ms/step - loss: 0.6517 - binary_accuracy: 0.6253 - false_negatives_8: 14252.0000 - false_positives_8: 3602.0000 - val_loss: 0.6605 - val_binary_accuracy: 0.5897 - val_false_negatives_8: 3068.0000 - val_false_positives_8: 1035.0000\n",
      "Epoch 26/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6499 - binary_accuracy: 0.6277 - false_negatives_8: 14094.0000 - false_positives_8: 3650.0000\n",
      "Epoch 26: val_loss improved from 0.66052 to 0.65968, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 317ms/step - loss: 0.6499 - binary_accuracy: 0.6277 - false_negatives_8: 14094.0000 - false_positives_8: 3650.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.5942 - val_false_negatives_8: 3038.0000 - val_false_positives_8: 1020.0000\n",
      "Epoch 27/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6500 - binary_accuracy: 0.6274 - false_negatives_8: 14084.0000 - false_positives_8: 3674.0000\n",
      "Epoch 27: val_loss improved from 0.65968 to 0.65878, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 57s 306ms/step - loss: 0.6500 - binary_accuracy: 0.6274 - false_negatives_8: 14084.0000 - false_positives_8: 3674.0000 - val_loss: 0.6588 - val_binary_accuracy: 0.5985 - val_false_negatives_8: 2981.0000 - val_false_positives_8: 1034.0000\n",
      "Epoch 28/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6490 - binary_accuracy: 0.6305 - false_negatives_8: 13894.0000 - false_positives_8: 3715.0000\n",
      "Epoch 28: val_loss improved from 0.65878 to 0.65791, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6490 - binary_accuracy: 0.6305 - false_negatives_8: 13894.0000 - false_positives_8: 3715.0000 - val_loss: 0.6579 - val_binary_accuracy: 0.6049 - val_false_negatives_8: 2925.0000 - val_false_positives_8: 1026.0000\n",
      "Epoch 29/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6479 - binary_accuracy: 0.6324 - false_negatives_8: 13784.0000 - false_positives_8: 3734.0000\n",
      "Epoch 29: val_loss improved from 0.65791 to 0.65705, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 316ms/step - loss: 0.6479 - binary_accuracy: 0.6324 - false_negatives_8: 13784.0000 - false_positives_8: 3734.0000 - val_loss: 0.6570 - val_binary_accuracy: 0.6106 - val_false_negatives_8: 2872.0000 - val_false_positives_8: 1022.0000\n",
      "Epoch 30/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6471 - binary_accuracy: 0.6336 - false_negatives_8: 13671.0000 - false_positives_8: 3789.0000\n",
      "Epoch 30: val_loss improved from 0.65705 to 0.65610, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.6471 - binary_accuracy: 0.6336 - false_negatives_8: 13671.0000 - false_positives_8: 3789.0000 - val_loss: 0.6561 - val_binary_accuracy: 0.6209 - val_false_negatives_8: 2798.0000 - val_false_positives_8: 993.0000\n",
      "Epoch 31/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6470 - binary_accuracy: 0.6341 - false_negatives_8: 13672.0000 - false_positives_8: 3763.0000\n",
      "Epoch 31: val_loss improved from 0.65610 to 0.65517, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.6470 - binary_accuracy: 0.6341 - false_negatives_8: 13672.0000 - false_positives_8: 3763.0000 - val_loss: 0.6552 - val_binary_accuracy: 0.6253 - val_false_negatives_8: 2725.0000 - val_false_positives_8: 1022.0000\n",
      "Epoch 32/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6452 - binary_accuracy: 0.6377 - false_negatives_8: 13437.0000 - false_positives_8: 3827.0000\n",
      "Epoch 32: val_loss improved from 0.65517 to 0.65420, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 316ms/step - loss: 0.6452 - binary_accuracy: 0.6377 - false_negatives_8: 13437.0000 - false_positives_8: 3827.0000 - val_loss: 0.6542 - val_binary_accuracy: 0.6298 - val_false_negatives_8: 2636.0000 - val_false_positives_8: 1066.0000\n",
      "Epoch 33/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6446 - binary_accuracy: 0.6378 - false_negatives_8: 13316.0000 - false_positives_8: 3944.0000\n",
      "Epoch 33: val_loss improved from 0.65420 to 0.65321, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 59s 314ms/step - loss: 0.6446 - binary_accuracy: 0.6378 - false_negatives_8: 13316.0000 - false_positives_8: 3944.0000 - val_loss: 0.6532 - val_binary_accuracy: 0.6353 - val_false_negatives_8: 2570.0000 - val_false_positives_8: 1077.0000\n",
      "Epoch 34/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6436 - binary_accuracy: 0.6390 - false_negatives_8: 13273.0000 - false_positives_8: 3931.0000\n",
      "Epoch 34: val_loss improved from 0.65321 to 0.65225, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 58s 311ms/step - loss: 0.6436 - binary_accuracy: 0.6390 - false_negatives_8: 13273.0000 - false_positives_8: 3931.0000 - val_loss: 0.6523 - val_binary_accuracy: 0.6378 - val_false_negatives_8: 2462.0000 - val_false_positives_8: 1160.0000\n",
      "Epoch 35/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6422 - binary_accuracy: 0.6398 - false_negatives_8: 13100.0000 - false_positives_8: 4063.0000\n",
      "Epoch 35: val_loss improved from 0.65225 to 0.65121, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 60s 320ms/step - loss: 0.6422 - binary_accuracy: 0.6398 - false_negatives_8: 13100.0000 - false_positives_8: 4063.0000 - val_loss: 0.6512 - val_binary_accuracy: 0.6436 - val_false_negatives_8: 2410.0000 - val_false_positives_8: 1154.0000\n",
      "Epoch 36/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6423 - binary_accuracy: 0.6399 - false_negatives_8: 13115.0000 - false_positives_8: 4046.0000\n",
      "Epoch 36: val_loss improved from 0.65121 to 0.65019, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 66s 352ms/step - loss: 0.6423 - binary_accuracy: 0.6399 - false_negatives_8: 13115.0000 - false_positives_8: 4046.0000 - val_loss: 0.6502 - val_binary_accuracy: 0.6523 - val_false_negatives_8: 2296.0000 - val_false_positives_8: 1181.0000\n",
      "Epoch 37/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6409 - binary_accuracy: 0.6429 - false_negatives_8: 12948.0000 - false_positives_8: 4070.0000\n",
      "Epoch 37: val_loss improved from 0.65019 to 0.64916, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 68s 362ms/step - loss: 0.6409 - binary_accuracy: 0.6429 - false_negatives_8: 12948.0000 - false_positives_8: 4070.0000 - val_loss: 0.6492 - val_binary_accuracy: 0.6554 - val_false_negatives_8: 2192.0000 - val_false_positives_8: 1254.0000\n",
      "Epoch 38/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.6467 - false_negatives_8: 12713.0000 - false_positives_8: 4125.0000\n",
      "Epoch 38: val_loss improved from 0.64916 to 0.64806, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 61s 325ms/step - loss: 0.6393 - binary_accuracy: 0.6467 - false_negatives_8: 12713.0000 - false_positives_8: 4125.0000 - val_loss: 0.6481 - val_binary_accuracy: 0.6587 - val_false_negatives_8: 2115.0000 - val_false_positives_8: 1298.0000\n",
      "Epoch 39/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6388 - binary_accuracy: 0.6432 - false_negatives_8: 12759.0000 - false_positives_8: 4243.0000\n",
      "Epoch 39: val_loss improved from 0.64806 to 0.64693, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 61s 328ms/step - loss: 0.6388 - binary_accuracy: 0.6432 - false_negatives_8: 12759.0000 - false_positives_8: 4243.0000 - val_loss: 0.6469 - val_binary_accuracy: 0.6625 - val_false_negatives_8: 2063.0000 - val_false_positives_8: 1312.0000\n",
      "Epoch 40/40\n",
      "187/187 [==============================] - ETA: 0s - loss: 0.6374 - binary_accuracy: 0.6475 - false_negatives_8: 12485.0000 - false_positives_8: 4312.0000\n",
      "Epoch 40: val_loss improved from 0.64693 to 0.64574, saving model to model/active/Adagrad_Model.h5\n",
      "187/187 [==============================] - 68s 364ms/step - loss: 0.6374 - binary_accuracy: 0.6475 - false_negatives_8: 12485.0000 - false_positives_8: 4312.0000 - val_loss: 0.6457 - val_binary_accuracy: 0.6651 - val_false_negatives_8: 2003.0000 - val_false_positives_8: 1346.0000\n",
      "40/40 [==============================] - 6s 127ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Number of zeros incorrectly classified: 2077.0, Number of ones incorrectly classified: 1054.0\n",
      "Sample ratio for positives: 0.33663366336633666, Sample ratio for negatives:0.6633663366336634\n",
      "Starting training with 51021 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6421 - binary_accuracy: 0.6410 - false_negatives_9: 13263.0000 - false_positives_9: 5056.0000\n",
      "Epoch 1: val_loss did not improve from 0.64574\n",
      "200/200 [==============================] - 76s 356ms/step - loss: 0.6421 - binary_accuracy: 0.6410 - false_negatives_9: 13263.0000 - false_positives_9: 5056.0000 - val_loss: 0.6471 - val_binary_accuracy: 0.6216 - val_false_negatives_9: 1549.0000 - val_false_positives_9: 2235.0000\n",
      "Epoch 2/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6393 - binary_accuracy: 0.6456 - false_negatives_9: 12212.0000 - false_positives_9: 5872.0000\n",
      "Epoch 2: val_loss improved from 0.64574 to 0.64460, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 66s 330ms/step - loss: 0.6393 - binary_accuracy: 0.6456 - false_negatives_9: 12212.0000 - false_positives_9: 5872.0000 - val_loss: 0.6446 - val_binary_accuracy: 0.6253 - val_false_negatives_9: 1553.0000 - val_false_positives_9: 2194.0000\n",
      "Epoch 3/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.6483 - false_negatives_9: 12046.0000 - false_positives_9: 5897.0000\n",
      "Epoch 3: val_loss improved from 0.64460 to 0.64289, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.6371 - binary_accuracy: 0.6483 - false_negatives_9: 12046.0000 - false_positives_9: 5897.0000 - val_loss: 0.6429 - val_binary_accuracy: 0.6252 - val_false_negatives_9: 1551.0000 - val_false_positives_9: 2197.0000\n",
      "Epoch 4/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6360 - binary_accuracy: 0.6506 - false_negatives_9: 11755.0000 - false_positives_9: 6070.0000\n",
      "Epoch 4: val_loss improved from 0.64289 to 0.64114, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 0.6360 - binary_accuracy: 0.6506 - false_negatives_9: 11755.0000 - false_positives_9: 6070.0000 - val_loss: 0.6411 - val_binary_accuracy: 0.6245 - val_false_negatives_9: 1547.0000 - val_false_positives_9: 2208.0000\n",
      "Epoch 5/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.6536 - false_negatives_9: 11559.0000 - false_positives_9: 6116.0000\n",
      "Epoch 5: val_loss improved from 0.64114 to 0.63884, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 0.6327 - binary_accuracy: 0.6536 - false_negatives_9: 11559.0000 - false_positives_9: 6116.0000 - val_loss: 0.6388 - val_binary_accuracy: 0.6271 - val_false_negatives_9: 1550.0000 - val_false_positives_9: 2179.0000\n",
      "Epoch 6/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6306 - binary_accuracy: 0.6562 - false_negatives_9: 11330.0000 - false_positives_9: 6213.0000\n",
      "Epoch 6: val_loss improved from 0.63884 to 0.63739, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 0.6306 - binary_accuracy: 0.6562 - false_negatives_9: 11330.0000 - false_positives_9: 6213.0000 - val_loss: 0.6374 - val_binary_accuracy: 0.6239 - val_false_negatives_9: 1533.0000 - val_false_positives_9: 2228.0000\n",
      "Epoch 7/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6278 - binary_accuracy: 0.6558 - false_negatives_9: 11099.0000 - false_positives_9: 6461.0000\n",
      "Epoch 7: val_loss improved from 0.63739 to 0.63482, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 69s 343ms/step - loss: 0.6278 - binary_accuracy: 0.6558 - false_negatives_9: 11099.0000 - false_positives_9: 6461.0000 - val_loss: 0.6348 - val_binary_accuracy: 0.6251 - val_false_negatives_9: 1525.0000 - val_false_positives_9: 2224.0000\n",
      "Epoch 8/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.6627 - false_negatives_9: 10772.0000 - false_positives_9: 6439.0000\n",
      "Epoch 8: val_loss improved from 0.63482 to 0.63295, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 0.6234 - binary_accuracy: 0.6627 - false_negatives_9: 10772.0000 - false_positives_9: 6439.0000 - val_loss: 0.6329 - val_binary_accuracy: 0.6220 - val_false_negatives_9: 1499.0000 - val_false_positives_9: 2281.0000\n",
      "Epoch 9/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6198 - binary_accuracy: 0.6641 - false_negatives_9: 10405.0000 - false_positives_9: 6733.0000\n",
      "Epoch 9: val_loss improved from 0.63295 to 0.62800, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 0.6198 - binary_accuracy: 0.6641 - false_negatives_9: 10405.0000 - false_positives_9: 6733.0000 - val_loss: 0.6280 - val_binary_accuracy: 0.6283 - val_false_negatives_9: 1432.0000 - val_false_positives_9: 2285.0000\n",
      "Epoch 10/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6090 - binary_accuracy: 0.6811 - false_negatives_9: 9373.0000 - false_positives_9: 6897.0000\n",
      "Epoch 10: val_loss improved from 0.62800 to 0.61658, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 72s 360ms/step - loss: 0.6090 - binary_accuracy: 0.6811 - false_negatives_9: 9373.0000 - false_positives_9: 6897.0000 - val_loss: 0.6166 - val_binary_accuracy: 0.6557 - val_false_negatives_9: 1115.0000 - val_false_positives_9: 2328.0000\n",
      "Epoch 11/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5961 - binary_accuracy: 0.6961 - false_negatives_9: 7632.0000 - false_positives_9: 7875.0000\n",
      "Epoch 11: val_loss did not improve from 0.61658\n",
      "200/200 [==============================] - 73s 367ms/step - loss: 0.5961 - binary_accuracy: 0.6961 - false_negatives_9: 7632.0000 - false_positives_9: 7875.0000 - val_loss: 0.6300 - val_binary_accuracy: 0.6488 - val_false_negatives_9: 675.0000 - val_false_positives_9: 2837.0000\n",
      "Epoch 12/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5890 - binary_accuracy: 0.7037 - false_negatives_9: 6790.0000 - false_positives_9: 8328.0000\n",
      "Epoch 12: val_loss improved from 0.61658 to 0.61404, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 76s 380ms/step - loss: 0.5890 - binary_accuracy: 0.7037 - false_negatives_9: 6790.0000 - false_positives_9: 8328.0000 - val_loss: 0.6140 - val_binary_accuracy: 0.6591 - val_false_negatives_9: 691.0000 - val_false_positives_9: 2718.0000\n",
      "Epoch 13/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5838 - binary_accuracy: 0.7083 - false_negatives_9: 6560.0000 - false_positives_9: 8323.0000\n",
      "Epoch 13: val_loss improved from 0.61404 to 0.60628, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 0.5838 - binary_accuracy: 0.7083 - false_negatives_9: 6560.0000 - false_positives_9: 8323.0000 - val_loss: 0.6063 - val_binary_accuracy: 0.6664 - val_false_negatives_9: 727.0000 - val_false_positives_9: 2609.0000\n",
      "Epoch 14/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5803 - binary_accuracy: 0.7139 - false_negatives_9: 6457.0000 - false_positives_9: 8141.0000\n",
      "Epoch 14: val_loss improved from 0.60628 to 0.60060, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.5803 - binary_accuracy: 0.7139 - false_negatives_9: 6457.0000 - false_positives_9: 8141.0000 - val_loss: 0.6006 - val_binary_accuracy: 0.6779 - val_false_negatives_9: 714.0000 - val_false_positives_9: 2507.0000\n",
      "Epoch 15/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5757 - binary_accuracy: 0.7190 - false_negatives_9: 6229.0000 - false_positives_9: 8106.0000\n",
      "Epoch 15: val_loss did not improve from 0.60060\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.5757 - binary_accuracy: 0.7190 - false_negatives_9: 6229.0000 - false_positives_9: 8106.0000 - val_loss: 0.6142 - val_binary_accuracy: 0.6626 - val_false_negatives_9: 600.0000 - val_false_positives_9: 2774.0000\n",
      "Epoch 16/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5705 - binary_accuracy: 0.7227 - false_negatives_9: 5976.0000 - false_positives_9: 8172.0000\n",
      "Epoch 16: val_loss improved from 0.60060 to 0.59989, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 58s 287ms/step - loss: 0.5705 - binary_accuracy: 0.7227 - false_negatives_9: 5976.0000 - false_positives_9: 8172.0000 - val_loss: 0.5999 - val_binary_accuracy: 0.6751 - val_false_negatives_9: 609.0000 - val_false_positives_9: 2640.0000\n",
      "Epoch 17/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5668 - binary_accuracy: 0.7257 - false_negatives_9: 5846.0000 - false_positives_9: 8150.0000\n",
      "Epoch 17: val_loss improved from 0.59989 to 0.59307, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.5668 - binary_accuracy: 0.7257 - false_negatives_9: 5846.0000 - false_positives_9: 8150.0000 - val_loss: 0.5931 - val_binary_accuracy: 0.6856 - val_false_negatives_9: 605.0000 - val_false_positives_9: 2539.0000\n",
      "Epoch 18/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5624 - binary_accuracy: 0.7291 - false_negatives_9: 5756.0000 - false_positives_9: 8068.0000\n",
      "Epoch 18: val_loss improved from 0.59307 to 0.57734, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.5624 - binary_accuracy: 0.7291 - false_negatives_9: 5756.0000 - false_positives_9: 8068.0000 - val_loss: 0.5773 - val_binary_accuracy: 0.7255 - val_false_negatives_9: 647.0000 - val_false_positives_9: 2098.0000\n",
      "Epoch 19/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5575 - binary_accuracy: 0.7345 - false_negatives_9: 5509.0000 - false_positives_9: 8039.0000\n",
      "Epoch 19: val_loss did not improve from 0.57734\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.5575 - binary_accuracy: 0.7345 - false_negatives_9: 5509.0000 - false_positives_9: 8039.0000 - val_loss: 0.5814 - val_binary_accuracy: 0.7030 - val_false_negatives_9: 587.0000 - val_false_positives_9: 2383.0000\n",
      "Epoch 20/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5513 - binary_accuracy: 0.7385 - false_negatives_9: 5408.0000 - false_positives_9: 7936.0000\n",
      "Epoch 20: val_loss did not improve from 0.57734\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.5513 - binary_accuracy: 0.7385 - false_negatives_9: 5408.0000 - false_positives_9: 7936.0000 - val_loss: 0.5821 - val_binary_accuracy: 0.6984 - val_false_negatives_9: 546.0000 - val_false_positives_9: 2470.0000\n",
      "Epoch 21/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5469 - binary_accuracy: 0.7451 - false_negatives_9: 5206.0000 - false_positives_9: 7798.0000\n",
      "Epoch 21: val_loss improved from 0.57734 to 0.57537, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.5469 - binary_accuracy: 0.7451 - false_negatives_9: 5206.0000 - false_positives_9: 7798.0000 - val_loss: 0.5754 - val_binary_accuracy: 0.7086 - val_false_negatives_9: 536.0000 - val_false_positives_9: 2378.0000\n",
      "Epoch 22/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5412 - binary_accuracy: 0.7519 - false_negatives_9: 4971.0000 - false_positives_9: 7689.0000\n",
      "Epoch 22: val_loss improved from 0.57537 to 0.57073, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.5412 - binary_accuracy: 0.7519 - false_negatives_9: 4971.0000 - false_positives_9: 7689.0000 - val_loss: 0.5707 - val_binary_accuracy: 0.7151 - val_false_negatives_9: 531.0000 - val_false_positives_9: 2318.0000\n",
      "Epoch 23/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5339 - binary_accuracy: 0.7583 - false_negatives_9: 4801.0000 - false_positives_9: 7532.0000\n",
      "Epoch 23: val_loss did not improve from 0.57073\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.5339 - binary_accuracy: 0.7583 - false_negatives_9: 4801.0000 - false_positives_9: 7532.0000 - val_loss: 0.5897 - val_binary_accuracy: 0.6807 - val_false_negatives_9: 458.0000 - val_false_positives_9: 2735.0000\n",
      "Epoch 24/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5279 - binary_accuracy: 0.7648 - false_negatives_9: 4643.0000 - false_positives_9: 7356.0000\n",
      "Epoch 24: val_loss did not improve from 0.57073\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.5279 - binary_accuracy: 0.7648 - false_negatives_9: 4643.0000 - false_positives_9: 7356.0000 - val_loss: 0.5708 - val_binary_accuracy: 0.7064 - val_false_negatives_9: 459.0000 - val_false_positives_9: 2477.0000\n",
      "Epoch 25/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5208 - binary_accuracy: 0.7708 - false_negatives_9: 4421.0000 - false_positives_9: 7272.0000\n",
      "Epoch 25: val_loss improved from 0.57073 to 0.55369, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.5208 - binary_accuracy: 0.7708 - false_negatives_9: 4421.0000 - false_positives_9: 7272.0000 - val_loss: 0.5537 - val_binary_accuracy: 0.7577 - val_false_negatives_9: 749.0000 - val_false_positives_9: 1674.0000\n",
      "Epoch 26/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5166 - binary_accuracy: 0.7740 - false_negatives_9: 4344.0000 - false_positives_9: 7185.0000\n",
      "Epoch 26: val_loss improved from 0.55369 to 0.54938, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 59s 296ms/step - loss: 0.5166 - binary_accuracy: 0.7740 - false_negatives_9: 4344.0000 - false_positives_9: 7185.0000 - val_loss: 0.5494 - val_binary_accuracy: 0.7580 - val_false_negatives_9: 724.0000 - val_false_positives_9: 1696.0000\n",
      "Epoch 27/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5098 - binary_accuracy: 0.7803 - false_negatives_9: 4289.0000 - false_positives_9: 6921.0000\n",
      "Epoch 27: val_loss did not improve from 0.54938\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 0.5098 - binary_accuracy: 0.7803 - false_negatives_9: 4289.0000 - false_positives_9: 6921.0000 - val_loss: 0.5612 - val_binary_accuracy: 0.7110 - val_false_negatives_9: 443.0000 - val_false_positives_9: 2447.0000\n",
      "Epoch 28/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5023 - binary_accuracy: 0.7872 - false_negatives_9: 4235.0000 - false_positives_9: 6620.0000\n",
      "Epoch 28: val_loss improved from 0.54938 to 0.53553, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 70s 352ms/step - loss: 0.5023 - binary_accuracy: 0.7872 - false_negatives_9: 4235.0000 - false_positives_9: 6620.0000 - val_loss: 0.5355 - val_binary_accuracy: 0.7671 - val_false_negatives_9: 709.0000 - val_false_positives_9: 1620.0000\n",
      "Epoch 29/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4908 - binary_accuracy: 0.7952 - false_negatives_9: 4352.0000 - false_positives_9: 6095.0000\n",
      "Epoch 29: val_loss improved from 0.53553 to 0.53027, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 0.4908 - binary_accuracy: 0.7952 - false_negatives_9: 4352.0000 - false_positives_9: 6095.0000 - val_loss: 0.5303 - val_binary_accuracy: 0.7589 - val_false_negatives_9: 646.0000 - val_false_positives_9: 1765.0000\n",
      "Epoch 30/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4818 - binary_accuracy: 0.8062 - false_negatives_9: 4269.0000 - false_positives_9: 5618.0000\n",
      "Epoch 30: val_loss did not improve from 0.53027\n",
      "200/200 [==============================] - 77s 386ms/step - loss: 0.4818 - binary_accuracy: 0.8062 - false_negatives_9: 4269.0000 - false_positives_9: 5618.0000 - val_loss: 0.5471 - val_binary_accuracy: 0.7228 - val_false_negatives_9: 569.0000 - val_false_positives_9: 2203.0000\n",
      "Epoch 31/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4733 - binary_accuracy: 0.8138 - false_negatives_9: 4121.0000 - false_positives_9: 5378.0000\n",
      "Epoch 31: val_loss improved from 0.53027 to 0.51951, saving model to model/active/Adagrad_Model.h5\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 0.4733 - binary_accuracy: 0.8138 - false_negatives_9: 4121.0000 - false_positives_9: 5378.0000 - val_loss: 0.5195 - val_binary_accuracy: 0.7655 - val_false_negatives_9: 643.0000 - val_false_positives_9: 1702.0000\n",
      "Epoch 32/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4642 - binary_accuracy: 0.8190 - false_negatives_9: 4051.0000 - false_positives_9: 5183.0000\n",
      "Epoch 32: val_loss did not improve from 0.51951\n",
      "200/200 [==============================] - 86s 432ms/step - loss: 0.4642 - binary_accuracy: 0.8190 - false_negatives_9: 4051.0000 - false_positives_9: 5183.0000 - val_loss: 0.5215 - val_binary_accuracy: 0.7551 - val_false_negatives_9: 663.0000 - val_false_positives_9: 1786.0000\n",
      "Epoch 33/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4577 - binary_accuracy: 0.8228 - false_negatives_9: 4123.0000 - false_positives_9: 4917.0000\n",
      "Epoch 33: val_loss did not improve from 0.51951\n",
      "200/200 [==============================] - 75s 377ms/step - loss: 0.4577 - binary_accuracy: 0.8228 - false_negatives_9: 4123.0000 - false_positives_9: 4917.0000 - val_loss: 0.5327 - val_binary_accuracy: 0.7279 - val_false_negatives_9: 492.0000 - val_false_positives_9: 2229.0000\n",
      "Epoch 34/40\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4505 - binary_accuracy: 0.8281 - false_negatives_9: 3928.0000 - false_positives_9: 4840.0000"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for optimizer in [\"Adadelta\", \"Adagrad\", \"Adamax\", \"Adafactor\", \"Nadam\", \"Ftri\"]:\n",
    "    model, results = train_active_learning_models(\n",
    "        train_dataset, pool_negatives, pool_positives, val_dataset, test_dataset, optimizer\n",
    "    )\n",
    "    results_dict[optimizer] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A string input\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
    "# Turn strings into vocab indices\n",
    "indices = vectorizer(inputs)\n",
    "# Turn vocab indices into predictions\n",
    "outputs = model(indices)\n",
    "\n",
    "# Our end to end model\n",
    "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "end_to_end_model.save('model/model_keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1f5d89d31c60f736a5f3bf2293aeb816f54929d0c7c26f09073a8ca847dae0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
